{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Epsilon-Greedy Latent Recommender</center></h1>\n",
    "\n",
    "<center><a href=\"https://www.kaggle.com/hamzael1\">Hamza El Bouatmani</a> on 14th April, 2019 </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Last Update 23th April*: *Code Refactoring, Evaluation Section & more Documentation added*\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "<a href=\"https://www.careervillage.org/\" target=\"_blank\">CareerVillage.org</a> <span style=\"color: purple;\">is a cloud-based solution for career advice</span>. It provides a platform where students with career-related questions meet professionals from the industry who help them by answering their questions.\n",
    "\n",
    "The goal of <a href=\"https://www.kaggle.com/c/data-science-for-good-careervillage/overview\" target=\"_blank\">this competition</a>, is to develop a method to recommend relevant questions to the professionals who are most likely to answer them.\n",
    "\n",
    "In this notebook, I propose a solution that addresses the problem in an efficient manner using a probabilistic approach (Epsilon-Greedy) combined with an *state-of-the-art technique (LSA)*. **This combination aims to balance between Exploration & Exploitation, targeting both the new and already-engaged professionals.**\n",
    "\n",
    "The biggest strength that was noticed, is that **this solution behaves particularly well when encountering professionals with diverse interests. For example, when a professional follows a set of tags, and answers questions unrelated to those tags, the system still keeps recommending questions from both ends, adapts continuously to the interests of the professional along time and behaves in a resilient manner.**\n",
    "\n",
    "Controlled randomness is inherent to the proposed approach, this has two advantages:\n",
    "* recommendations stay diverse.\n",
    "* unanswered new questions have a high chance to get answered because they get propritized. The model doesn't *over-focus* on the answered questions of the professionals.\n",
    "\n",
    "Further, a basic framework for evaluating the system was proposed along with the most important metrics to measure. This helps fine-tune the model parameters locally before moving to production and gives and idea about the performance of the system.\n",
    "\n",
    "This notebook is structured as follows:\n",
    "* First, we ask the question \"[Why do we need a Recommender?](#why)\" and answer it with some focused analytics.\n",
    "* Next, [techniques and concepts](#concepts) used in the proposed recommender are explained.\n",
    "* Then, we move to the actual [implementation of the proposed recommender system and explain its inner-workings](#implementation) after performing the necessary [proprocessings](#preproc).\n",
    "* We discuss the difficulty of evaluating Recommender Systems and [propose a very basic framework to evaluate the proposed system](#eval), along with the metrics that must be took into account.\n",
    "* Finally, some [advice and future suggestions for improving the system](#future) are listed, along with links to useful ressources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "# Why do we need a Recommender ? Let's ask the Data ! <a class=\"anchor\" id=\"why\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/hamzael1/an-extensive-eda-for-careervillage\" target=\"_blank\">In a previous notebook</a> I made an overall Exploratory Data Analysis on the provided data. Here, I will be brief and focus on the most important statistics and metrics related to the recommendation problem.\n",
    "\n",
    "*Note: some code snippets that are trivial are collapsed for better readability, feel free to expand them if you want to check the code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important numbers:\n",
      "\n",
      "There are:\n",
      "- 30971 Students.\t- 28152 Professionals.\n",
      "- 23931 Questions.\t- 51123 Answers.\n",
      "- 16269 Tags.\t\t- 14966 Comments.\n",
      "- 2706 Schools.\t\t- 49 Groups.\n",
      "- 1850101 Emails were sent.\n",
      "\n",
      "Interesting statistics: \n",
      "- 96.57 % of the questions have at least 1 answer.\n",
      "\n",
      "- 97.31% of questions are tagged by at least 1 tag.\n",
      "- Mean of tags per question: 3.29 tags per question.\n",
      "\n",
      "- 90.91 % of the professionals follow at least 1 Tag (25594).\n",
      "- 14.88 % of the students follow at least 1 Tag (4608).\n",
      "\n",
      "- 96.93 % of questions were upvoted (23196).\n",
      "- 57.82 % of answers were upvoted (13837).\n",
      "\n",
      "- Only 0.04 % of the students are members of schools (1355).\n",
      "- Only 0.15 % of the professionals are members of schools (4283).\n",
      "\n",
      "- Only 0.01 % of the students are members of groups (311).\n",
      "- Only 0.03 % of the professionals are members of groups (727).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import random\n",
    "from random import choice, choices\n",
    "import time\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Professionals Import\n",
    "\n",
    "professionals = pd.read_csv('../input/professionals.csv', index_col='professionals_id')\n",
    "professionals = professionals.rename(columns={'professionals_location': 'location', 'professionals_industry': 'industry', 'professionals_headline': 'headline', 'professionals_date_joined': 'date_joined'})\n",
    "professionals['headline'] = professionals['headline'].fillna('')\n",
    "professionals['industry'] = professionals['industry'].fillna('')\n",
    "\n",
    "# Students Import\n",
    "\n",
    "students = pd.read_csv('../input/students.csv', index_col='students_id')\n",
    "students = students.rename(columns={'students_location': 'location', 'students_date_joined': 'date_joined'})\n",
    "\n",
    "# Questions Import\n",
    "questions = pd.read_csv('../input/questions.csv', index_col='questions_id', parse_dates=['questions_date_added'], infer_datetime_format=True)\n",
    "questions = questions.rename(columns={'questions_author_id': 'author_id', 'questions_date_added': 'date_added', 'questions_title': 'title', 'questions_body': 'body', 'questions_processed':'processed'})\n",
    "\n",
    "# Answers Import\n",
    "answers = pd.read_csv('../input/answers.csv', index_col='answers_id', parse_dates=['answers_date_added'], infer_datetime_format=True)\n",
    "answers = answers.rename(columns={'answers_author_id':'author_id', 'answers_question_id': 'question_id', 'answers_date_added': 'date_added', 'answers_body': 'body'})\n",
    "\n",
    "# Tags Import\n",
    "tags = pd.read_csv('../input/tags.csv',)\n",
    "tags = tags.set_index('tags_tag_id')\n",
    "tags = tags.rename(columns={'tags_tag_name': 'name'})\n",
    "\n",
    "# Comments Import\n",
    "comments = pd.read_csv('../input/comments.csv', index_col='comments_id')\n",
    "comments = comments.rename(columns={'comments_author_id': 'author_id', 'comments_parent_content_id': 'parent_content_id', 'comments_date_added': 'date_added', 'comments_body': 'body' })\n",
    "\n",
    "\n",
    "# School Memberships\n",
    "school_memberships = pd.read_csv('../input/school_memberships.csv')\n",
    "school_memberships = school_memberships.rename(columns={'school_memberships_school_id': 'school_id', 'school_memberships_user_id': 'user_id'})\n",
    "\n",
    "# Groups Memberships\n",
    "group_memberships = pd.read_csv('../input/group_memberships.csv')\n",
    "group_memberships = group_memberships.rename(columns={'group_memberships_group_id': 'group_id', 'group_memberships_user_id': 'user_id'})\n",
    "\n",
    "# Emails\n",
    "emails = pd.read_csv('../input/emails.csv')\n",
    "emails = emails.set_index('emails_id')\n",
    "emails = emails.rename(columns={'emails_recipient_id':'recipient_id', 'emails_date_sent': 'date_sent', 'emails_frequency_level': 'frequency_level'})\n",
    "\n",
    "#####################################################\n",
    "print('Important numbers:')\n",
    "print('\\nThere are:')\n",
    "print(f'- {len(students)} Students.', end=\"\\t\")\n",
    "print(f'- {len(professionals)} Professionals.')\n",
    "print(f'- {len(questions)} Questions.', end=\"\\t\")\n",
    "print(f'- {len(answers)} Answers.')\n",
    "print(f'- {len(tags)} Tags.', end=\"\\t\\t\")\n",
    "print(f'- {len(comments)} Comments.')\n",
    "print(f'- {school_memberships[\"school_id\"].nunique()} Schools.', end=\"\\t\\t\")\n",
    "print(f'- {len(pd.read_csv(\"../input/groups.csv\"))} Groups.')\n",
    "print(f'- {len(emails)} Emails were sent.')\n",
    "#####################################################\n",
    "\n",
    "# Questions-related stats\n",
    "tag_questions = pd.read_csv('../input/tag_questions.csv',)\n",
    "tag_questions = tag_questions.rename(columns={'tag_questions_tag_id': 'tag_id', 'tag_questions_question_id': 'question_id'})\n",
    "count_question_tags = tag_questions.groupby('question_id').count().rename(columns={'tag_id': 'count_tags'}).sort_values('count_tags', ascending=False)\n",
    "print('\\nInteresting statistics: ')\n",
    "print(f'- {(answers[\"question_id\"].nunique()/len(questions))*100:.2f} % of the questions have at least 1 answer.')\n",
    "print(f'\\n- {(len(count_question_tags)/len(questions))*100:.2f}% of questions are tagged by at least {count_question_tags[\"count_tags\"].tail(1).values[0]} tag.')\n",
    "print(f'- Mean of tags per question: {count_question_tags[\"count_tags\"].mean():.2f} tags per question.')\n",
    "\n",
    "tag_users = pd.read_csv('../input/tag_users.csv',)\n",
    "tag_users = tag_users.rename(columns={'tag_users_tag_id': 'tag_id', 'tag_users_user_id': 'user_id'})\n",
    "users_who_follow_tags = list(tag_users['user_id'].unique())\n",
    "nbr_pros_tags = len(professionals[professionals.index.isin(users_who_follow_tags)])\n",
    "nbr_students_tags = len(students[students.index.isin(users_who_follow_tags)])\n",
    "print(f'\\n- {(nbr_pros_tags / len(professionals))*100:.2f} % of the professionals follow at least 1 Tag ({nbr_pros_tags}).')\n",
    "print(f'- {(nbr_students_tags / len(students))*100:.2f} % of the students follow at least 1 Tag ({nbr_students_tags}).')\n",
    "\n",
    "question_scores = pd.read_csv('../input/question_scores.csv')\n",
    "nbr_questions_with_hearts = question_scores[question_scores['score'] > 0]['id'].nunique()\n",
    "print(f'\\n- {(nbr_questions_with_hearts/len(questions))*100:.2f} % of questions were upvoted ({nbr_questions_with_hearts}).')\n",
    "\n",
    "answer_scores = pd.read_csv('../input/answer_scores.csv')\n",
    "nbr_answers_with_hearts = answer_scores[answer_scores['score'] > 0]['id'].nunique()\n",
    "print(f'- {(nbr_answers_with_hearts/len(questions))*100:.2f} % of answers were upvoted ({nbr_answers_with_hearts}).')\n",
    "\n",
    "\n",
    "# School/Group Related Stats\n",
    "\n",
    "def is_student(user_id):\n",
    "    if user_id in students.index.values:\n",
    "        return 1\n",
    "    elif user_id in professionals.index.values:\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError('User ID not student & not professional')\n",
    "\n",
    "school_memberships['is_student'] = school_memberships['user_id'].apply(is_student)\n",
    "school_memberships['is_student'] = school_memberships['is_student'].astype(int)\n",
    "count_students_professionals = school_memberships.groupby('is_student').count()[['school_id']].rename(columns={'school_id':'count'})\n",
    "print(f'\\n- Only {count_students_professionals.loc[1].values[0]/len(students):.2f} % of the students are members of schools ({count_students_professionals.loc[1].values[0]}).')\n",
    "print(f'- Only {count_students_professionals.loc[0].values[0]/len(professionals):.2f} % of the professionals are members of schools ({count_students_professionals.loc[0].values[0]}).')\n",
    "\n",
    "group_memberships['is_student'] = group_memberships['user_id'].apply(is_student)\n",
    "group_memberships['is_student'] = group_memberships['is_student'].astype(int)\n",
    "count_students_professionals = group_memberships.groupby('is_student').count()[['group_id']].rename(columns={'group_id':'count'})\n",
    "print(f'\\n- Only {count_students_professionals.loc[1].values[0]/len(students):.2f} % of the students are members of groups ({count_students_professionals.loc[1].values[0]}).')\n",
    "print(f'- Only {count_students_professionals.loc[0].values[0]/len(professionals):.2f} % of the professionals are members of groups ({count_students_professionals.loc[0].values[0]}).')\n",
    "\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Need to increase the number of active professionals:\n",
    "The following two graphs examine the degree activity of professionals in terms of number of posted answers.\n",
    "\n",
    "* The first Pie Chart shows that most of the professionals still haven't posted their first answer.\n",
    "* The second Bar Graph compares the number of active (posted at least one answer) and inactive (didn't post any answer) professionals each year.\n",
    "\n",
    "A good recommendation system can surely help professionals find relevant questions to answer and increase their activity on the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "labels": [
          "Zero answers",
          "> 0 answers"
         ],
         "marker": {
          "colors": [
           "#00FF66",
           "#D9BCDB"
          ],
          "line": {
           "color": "white",
           "width": 3
          }
         },
         "showlegend": false,
         "textinfo": "label+percent",
         "type": "pie",
         "uid": "ec7016c4-9916-4af7-a466-1c7f2dcac0da",
         "values": [
          17983,
          10169
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Professionals with Zero Answers"
        }
       }
      },
      "text/html": [
       "<div id=\"349f6478-fa97-470f-aff1-0023ba795edf\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"349f6478-fa97-470f-aff1-0023ba795edf\")) {\n",
       "    Plotly.newPlot(\"349f6478-fa97-470f-aff1-0023ba795edf\", [{\"labels\": [\"Zero answers\", \"> 0 answers\"], \"marker\": {\"colors\": [\"#00FF66\", \"#D9BCDB\"], \"line\": {\"color\": \"white\", \"width\": 3}}, \"showlegend\": false, \"textinfo\": \"label+percent\", \"values\": [17983, 10169], \"type\": \"pie\", \"uid\": \"425e8e91-87d2-4a32-9d6d-2b3a491817d5\"}], {\"title\": {\"text\": \"Professionals with Zero Answers\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"349f6478-fa97-470f-aff1-0023ba795edf\")) {window._Plotly.Plots.resize(document.getElementById(\"349f6478-fa97-470f-aff1-0023ba795edf\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"349f6478-fa97-470f-aff1-0023ba795edf\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"349f6478-fa97-470f-aff1-0023ba795edf\")) {\n",
       "    Plotly.newPlot(\"349f6478-fa97-470f-aff1-0023ba795edf\", [{\"labels\": [\"Zero answers\", \"> 0 answers\"], \"marker\": {\"colors\": [\"#00FF66\", \"#D9BCDB\"], \"line\": {\"color\": \"white\", \"width\": 3}}, \"showlegend\": false, \"textinfo\": \"label+percent\", \"values\": [17983, 10169], \"type\": \"pie\", \"uid\": \"425e8e91-87d2-4a32-9d6d-2b3a491817d5\"}], {\"title\": {\"text\": \"Professionals with Zero Answers\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"349f6478-fa97-470f-aff1-0023ba795edf\")) {window._Plotly.Plots.resize(document.getElementById(\"349f6478-fa97-470f-aff1-0023ba795edf\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Professionals with zero answers\n",
    "nbr_pros_without_answers = len(professionals) - answers['author_id'].nunique()\n",
    "#print(f'\\n- {(nbr_pros_without_answers/len(professionals))*100:.2f} % of the professionals have Zero answers ({nbr_pros_without_answers}).')\n",
    "fig = {\n",
    "    'data': [{\n",
    "        'type': 'pie',\n",
    "        'labels': ['Zero answers', '> 0 answers'],\n",
    "        'values': [nbr_pros_without_answers , len(professionals) - nbr_pros_without_answers],\n",
    "        'textinfo': 'label+percent',\n",
    "        'showlegend': False,\n",
    "        'marker': {'colors': [ '#00FF66', '#D9BCDB',], 'line': {'width': 3, 'color': 'white'}},\n",
    "    }],\n",
    "    'layout': {\n",
    "        'title': 'Professionals with Zero Answers'\n",
    "    }\n",
    "}\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "#db2d43"
         },
         "name": "Number of Active Professionals",
         "type": "bar",
         "uid": "67c148da-d102-4d53-a8c6-05cf48b2e942",
         "x": [
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019
         ],
         "y": [
          23,
          147,
          180,
          581,
          797,
          2679,
          3130,
          4094,
          413
         ]
        },
        {
         "marker": {
          "color": "#906FA8"
         },
         "name": "Number of Inactive Professionals",
         "type": "bar",
         "uid": "55ef6cc3-7916-445e-a5c7-a41cebc5210b",
         "x": [
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019
         ],
         "y": [
          34,
          132,
          528,
          1114,
          2438,
          6174,
          12045,
          22653,
          27739
         ]
        }
       ],
       "layout": {
        "barmode": "stack",
        "legend": {
         "orientation": "h"
        },
        "title": {
         "text": "Number of Active vs Non-Active Professionals each year"
        },
        "xaxis": {
         "title": {
          "text": "Years"
         }
        },
        "yaxis": {
         "title": {
          "text": "Number of Professionals"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"6eb6dd63-eff7-4798-9756-39bb591b19eb\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"6eb6dd63-eff7-4798-9756-39bb591b19eb\")) {\n",
       "    Plotly.newPlot(\"6eb6dd63-eff7-4798-9756-39bb591b19eb\", [{\"marker\": {\"color\": \"#db2d43\"}, \"name\": \"Number of Active Professionals\", \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [23, 147, 180, 581, 797, 2679, 3130, 4094, 413], \"type\": \"bar\", \"uid\": \"65bc42e6-dabb-4c38-b6f0-4962b3e7ed64\"}, {\"marker\": {\"color\": \"#906FA8\"}, \"name\": \"Number of Inactive Professionals\", \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [34, 132, 528, 1114, 2438, 6174, 12045, 22653, 27739], \"type\": \"bar\", \"uid\": \"692fc25e-117b-463e-8a87-922dafa3051b\"}], {\"barmode\": \"stack\", \"legend\": {\"orientation\": \"h\"}, \"title\": {\"text\": \"Number of Active vs Non-Active Professionals each year\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Number of Professionals\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"6eb6dd63-eff7-4798-9756-39bb591b19eb\")) {window._Plotly.Plots.resize(document.getElementById(\"6eb6dd63-eff7-4798-9756-39bb591b19eb\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"6eb6dd63-eff7-4798-9756-39bb591b19eb\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"6eb6dd63-eff7-4798-9756-39bb591b19eb\")) {\n",
       "    Plotly.newPlot(\"6eb6dd63-eff7-4798-9756-39bb591b19eb\", [{\"marker\": {\"color\": \"#db2d43\"}, \"name\": \"Number of Active Professionals\", \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [23, 147, 180, 581, 797, 2679, 3130, 4094, 413], \"type\": \"bar\", \"uid\": \"65bc42e6-dabb-4c38-b6f0-4962b3e7ed64\"}, {\"marker\": {\"color\": \"#906FA8\"}, \"name\": \"Number of Inactive Professionals\", \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [34, 132, 528, 1114, 2438, 6174, 12045, 22653, 27739], \"type\": \"bar\", \"uid\": \"692fc25e-117b-463e-8a87-922dafa3051b\"}], {\"barmode\": \"stack\", \"legend\": {\"orientation\": \"h\"}, \"title\": {\"text\": \"Number of Active vs Non-Active Professionals each year\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Number of Professionals\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"6eb6dd63-eff7-4798-9756-39bb591b19eb\")) {window._Plotly.Plots.resize(document.getElementById(\"6eb6dd63-eff7-4798-9756-39bb591b19eb\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answers Import\n",
    "years = questions['date_added'].dt.year.unique()\n",
    "years = sorted(years)\n",
    "professionals['date_joined'] = pd.to_datetime(professionals['date_joined'])\n",
    "activity_per_year = {}\n",
    "\n",
    "for y in years:\n",
    "#y = 2013\n",
    "    limit_date = pd.to_datetime(f'{y}-12-31') - np.timedelta64(200, 'D')\n",
    "    year_answers = answers[answers['date_added'].dt.year == y]\n",
    "    professionals_up_to_year = professionals[professionals['date_joined'].dt.year <= y]\n",
    "    \n",
    "    nbr_active_pros = year_answers['author_id'].nunique()\n",
    "    nbr_inactive_pros = len(professionals_up_to_year) - nbr_active_pros\n",
    "    activity_per_year[y] = (nbr_active_pros, nbr_inactive_pros)\n",
    "\n",
    "\n",
    "fig = {\n",
    "    'data': [\n",
    "        {\n",
    "        'type': 'bar',\n",
    "        'name': 'Number of Active Professionals',\n",
    "        'x': years,\n",
    "        'y': [e[0] for e in list(activity_per_year.values())],\n",
    "        'marker': {'color': '#db2d43'}\n",
    "        },\n",
    "        {\n",
    "        'type': 'bar',\n",
    "        'name': 'Number of Inactive Professionals',\n",
    "        'x': years,\n",
    "        'y': [e[1] for e in list(activity_per_year.values())],\n",
    "        'marker': {'color': '#906FA8'}\n",
    "        }\n",
    "    ],\n",
    "    'layout': {\n",
    "        'title': 'Number of Active vs Non-Active Professionals each year',\n",
    "        'xaxis': {'title': 'Years'},\n",
    "        'yaxis': {'title': 'Number of Professionals',},\n",
    "        'barmode': 'stack',\n",
    "        'legend': {'orientation': 'h'},\n",
    "    }\n",
    "}\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Mean Time-To-First-Answer. Can we do better ?\n",
    "The following graph shows the evolution of the means of Time-to-First-Answer for questions of each year. A good recommendation system must minimize this metric.\n",
    "\n",
    "**Mean Time-to-First-Answer**: $\\frac{1}{nbr \\thinspace questions}\\sum_{q}^{questions}{nbr \\thinspace days \\thinspace between \\thinspace question \\thinspace q \\thinspace was \\thinspace posted \\thinspace and \\thinspace its \\thinspace first \\thinspace answer}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "line": {
          "color": "#9250B0"
         },
         "type": "scatter",
         "uid": "6fe4157a-008c-4560-aa6b-95c2f2380bb0",
         "x": [
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019
         ],
         "y": [
          59.66146910919538,
          28.359825883354613,
          48.90281375324367,
          30.963589215767403,
          29.07802632036025,
          109.43998411169221,
          37.36001710311319,
          39.9203517742886,
          4.390634279654104
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Evolution of Time to First Response in days"
        },
        "xaxis": {
         "title": {
          "text": "Years"
         }
        },
        "yaxis": {
         "title": {
          "text": "Time to First Response"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"7df1ebeb-089d-45f4-85ac-ee39125909c5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"7df1ebeb-089d-45f4-85ac-ee39125909c5\")) {\n",
       "    Plotly.newPlot(\"7df1ebeb-089d-45f4-85ac-ee39125909c5\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [59.66146910919538, 28.359825883354613, 48.90281375324367, 30.963589215767403, 29.07802632036025, 109.43998411169221, 37.36001710311319, 39.9203517742886, 4.390634279654104], \"type\": \"scatter\", \"uid\": \"595b0dbb-59ea-4c34-8737-04fc06ab01cd\"}], {\"title\": {\"text\": \"Evolution of Time to First Response in days\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Time to First Response\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"7df1ebeb-089d-45f4-85ac-ee39125909c5\")) {window._Plotly.Plots.resize(document.getElementById(\"7df1ebeb-089d-45f4-85ac-ee39125909c5\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7df1ebeb-089d-45f4-85ac-ee39125909c5\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"7df1ebeb-089d-45f4-85ac-ee39125909c5\")) {\n",
       "    Plotly.newPlot(\"7df1ebeb-089d-45f4-85ac-ee39125909c5\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [59.66146910919538, 28.359825883354613, 48.90281375324367, 30.963589215767403, 29.07802632036025, 109.43998411169221, 37.36001710311319, 39.9203517742886, 4.390634279654104], \"type\": \"scatter\", \"uid\": \"595b0dbb-59ea-4c34-8737-04fc06ab01cd\"}], {\"title\": {\"text\": \"Evolution of Time to First Response in days\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Time to First Response\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"7df1ebeb-089d-45f4-85ac-ee39125909c5\")) {window._Plotly.Plots.resize(document.getElementById(\"7df1ebeb-089d-45f4-85ac-ee39125909c5\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers = answers.rename(columns={'date_added': 'answers_date_added'})\n",
    "questions = questions.rename(columns={'date_added': 'questions_date_added'})\n",
    "first_answers = answers[['question_id', 'answers_date_added']].groupby('question_id').min()\n",
    "answers_questions = first_answers.join(questions[['questions_date_added']])\n",
    "answers_questions['diff_days'] = (answers_questions['answers_date_added'] - answers_questions['questions_date_added'])/np.timedelta64(1,'D')\n",
    "vals = [answers_questions[answers_questions['questions_date_added'].dt.year == y]['diff_days'].mean() for y in years]\n",
    "LINE_COLOR = '#9250B0'\n",
    "fig = {\n",
    "    'data': [{\n",
    "        'type': 'scatter',\n",
    "        'x': years,\n",
    "        'y': vals,\n",
    "        'line': {'color': LINE_COLOR}\n",
    "    }],\n",
    "    'layout': {\n",
    "        'title': 'Evolution of Time to First Response in days',\n",
    "        'xaxis': {'title': 'Years'},\n",
    "        'yaxis': {'title': 'Time to First Response'}\n",
    "    }\n",
    "}\n",
    "iplot(fig)\n",
    "answers = answers.rename(columns={'answers_date_added': 'date_added'})\n",
    "questions = questions.rename(columns={'questions_date_added': 'date_added'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Number of accurate recommendations:\n",
    "Next, we examine how many accurate recommendations are sent each year. How many of them were answered by the recipients of the emails. Again, this number must be maximized by our recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "line": {
          "color": "#9250B0"
         },
         "type": "scatter",
         "uid": "f61be92d-bb7c-4236-9970-65c2e48614bd",
         "x": [
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019
         ],
         "y": [
          0,
          0,
          5,
          548,
          581,
          5309,
          5024,
          5672,
          264
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Evolution of Number of Accurate recommendations"
        },
        "xaxis": {
         "title": {
          "text": "Years"
         }
        },
        "yaxis": {
         "title": {
          "text": "Time to First Response"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"01172833-a252-4605-974a-b0ef3181f65d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"01172833-a252-4605-974a-b0ef3181f65d\")) {\n",
       "    Plotly.newPlot(\"01172833-a252-4605-974a-b0ef3181f65d\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [0, 0, 5, 548, 581, 5309, 5024, 5672, 264], \"type\": \"scatter\", \"uid\": \"377377e8-ec55-4a9d-a5a4-e19621ae1411\"}], {\"title\": {\"text\": \"Evolution of Number of Accurate recommendations\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Time to First Response\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"01172833-a252-4605-974a-b0ef3181f65d\")) {window._Plotly.Plots.resize(document.getElementById(\"01172833-a252-4605-974a-b0ef3181f65d\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"01172833-a252-4605-974a-b0ef3181f65d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"01172833-a252-4605-974a-b0ef3181f65d\")) {\n",
       "    Plotly.newPlot(\"01172833-a252-4605-974a-b0ef3181f65d\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [0, 0, 5, 548, 581, 5309, 5024, 5672, 264], \"type\": \"scatter\", \"uid\": \"377377e8-ec55-4a9d-a5a4-e19621ae1411\"}], {\"title\": {\"text\": \"Evolution of Number of Accurate recommendations\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"title\": {\"text\": \"Time to First Response\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"01172833-a252-4605-974a-b0ef3181f65d\")) {window._Plotly.Plots.resize(document.getElementById(\"01172833-a252-4605-974a-b0ef3181f65d\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of accurate recommendations\n",
    "emails['date_sent'] = pd.to_datetime(emails['date_sent'], infer_datetime_format=True)\n",
    "matches = pd.read_csv('../input/matches.csv')\n",
    "matches = matches.join(emails[['recipient_id', 'date_sent']], on='matches_email_id')\n",
    "\n",
    "matches = matches.rename(columns={'matches_question_id': 'question_id', 'matches_email_id': 'email_id'})\n",
    "all_recommendations_per_year = []\n",
    "accurate_recommendations_per_year = []\n",
    "matches['author_id'] = matches['recipient_id']\n",
    "for y in years:\n",
    "    year_answers = answers[answers['date_added'].dt.year == y]\n",
    "    year_recommendations = matches[matches['date_sent'].dt.year == y]\n",
    "    all_recommendations_per_year.append(len(year_recommendations))\n",
    "    m = year_answers.reset_index().merge(year_recommendations, on=['question_id', 'author_id']).set_index('answers_id')\n",
    "    nbr_accurate_recommendations = len(m)\n",
    "    accurate_recommendations_per_year.append(nbr_accurate_recommendations)\n",
    "    #print(f'- {(nbr_accurate_recommendations/len(matches))*100:.2f} % of recommended questions in emails were accurate (lead to professional answering the recommended question) ({nbr_accurate_recommendations})')\n",
    "\n",
    "#print(accurate_recommendations_per_year)\n",
    "LINE_COLOR = '#9250B0'\n",
    "fig = {\n",
    "    'data': [{\n",
    "        'type': 'scatter',\n",
    "        'x': years,\n",
    "        'y': accurate_recommendations_per_year,\n",
    "        'line': {'color': LINE_COLOR}\n",
    "    }],\n",
    "    'layout': {\n",
    "        'title': 'Evolution of Number of Accurate recommendations',\n",
    "        'xaxis': {'title': 'Years'},\n",
    "        'yaxis': {'title': 'Time to First Response'}\n",
    "    }\n",
    "}\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Proportion of accurate recommendations:\n",
    "\n",
    "The following graph plots the the Ratio of number of accurate recommendations over all recommendations made. We can see that even though an increase of number of accurate recommendations occured in 2016 (previous graph), it was due to a significant increase in recommendations made. Ideally, a good recommender should maximize the number of accurate recommendations and minimize the number of incorrect ones in order to avoid churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "line": {
          "color": "#9250B0"
         },
         "type": "scatter",
         "uid": "d3ab3565-cce7-4f02-a0e1-a41736406684",
         "x": [
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019
         ],
         "y": [
          0,
          0,
          0.040983606557377046,
          0.01966060345136871,
          0.009731830287599873,
          0.005554218758173354,
          0.004713967097935857,
          0.0027169305199626374,
          0.0022127231581594168
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Percentage of Accurate recommendations"
        },
        "xaxis": {
         "title": {
          "text": "Years"
         }
        },
        "yaxis": {
         "tickformat": ",.0%",
         "title": {
          "text": "Proportion of Accurate Recommendations"
         }
        }
       }
      },
      "text/html": [
       "<div id=\"d9752416-b99b-4880-ab49-7a965f5cd39d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"d9752416-b99b-4880-ab49-7a965f5cd39d\")) {\n",
       "    Plotly.newPlot(\"d9752416-b99b-4880-ab49-7a965f5cd39d\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [0, 0, 0.040983606557377046, 0.01966060345136871, 0.009731830287599873, 0.005554218758173354, 0.004713967097935857, 0.0027169305199626374, 0.0022127231581594168], \"type\": \"scatter\", \"uid\": \"48255730-b46b-463c-a40d-738d968f58fb\"}], {\"title\": {\"text\": \"Percentage of Accurate recommendations\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"tickformat\": \",.0%\", \"title\": {\"text\": \"Proportion of Accurate Recommendations\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"d9752416-b99b-4880-ab49-7a965f5cd39d\")) {window._Plotly.Plots.resize(document.getElementById(\"d9752416-b99b-4880-ab49-7a965f5cd39d\"));};})</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"d9752416-b99b-4880-ab49-7a965f5cd39d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";\n",
       "if (document.getElementById(\"d9752416-b99b-4880-ab49-7a965f5cd39d\")) {\n",
       "    Plotly.newPlot(\"d9752416-b99b-4880-ab49-7a965f5cd39d\", [{\"line\": {\"color\": \"#9250B0\"}, \"x\": [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019], \"y\": [0, 0, 0.040983606557377046, 0.01966060345136871, 0.009731830287599873, 0.005554218758173354, 0.004713967097935857, 0.0027169305199626374, 0.0022127231581594168], \"type\": \"scatter\", \"uid\": \"48255730-b46b-463c-a40d-738d968f58fb\"}], {\"title\": {\"text\": \"Percentage of Accurate recommendations\"}, \"xaxis\": {\"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"tickformat\": \",.0%\", \"title\": {\"text\": \"Proportion of Accurate Recommendations\"}}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"}); \n",
       "}\n",
       "});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){if (document.getElementById(\"d9752416-b99b-4880-ab49-7a965f5cd39d\")) {window._Plotly.Plots.resize(document.getElementById(\"d9752416-b99b-4880-ab49-7a965f5cd39d\"));};})</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "proportions_of_accurate_recommendations = np.array(accurate_recommendations_per_year)/np.array(all_recommendations_per_year)\n",
    "proportions_of_accurate_recommendations = [0 if np.isnan(e) else e for e in proportions_of_accurate_recommendations]\n",
    "#print(proportions_of_accurate_recommendations)\n",
    "fig = {\n",
    "    'data': [{\n",
    "        'type': 'scatter',\n",
    "        'x': years,\n",
    "        'y': proportions_of_accurate_recommendations,\n",
    "        'line': {'color': LINE_COLOR}\n",
    "    },\n",
    "    ],\n",
    "    'layout': {\n",
    "        'title': 'Percentage of Accurate recommendations',\n",
    "        'xaxis': {'title': 'Years'},\n",
    "        'yaxis': {'title': 'Proportion of Accurate Recommendations', 'tickformat': ',.0%'}\n",
    "    }\n",
    "}\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Garbadge collect stuff we won't be using for building the recommender.\n",
    "\n",
    "del m\n",
    "del emails\n",
    "del matches\n",
    "del students\n",
    "del school_memberships\n",
    "del group_memberships\n",
    "del count_question_tags\n",
    "del users_who_follow_tags\n",
    "del nbr_pros_tags\n",
    "del nbr_students_tags\n",
    "del nbr_pros_without_answers\n",
    "del nbr_questions_with_hearts\n",
    "del count_students_professionals\n",
    "gc.collect()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "* Tags are heavily used by students in questions.\n",
    "* Most professionals follow tags to find questions related to their expertise.\n",
    "* **Most of the professionals (~63%) haven't answered any question yet.**\n",
    "* **Only a tiny proportion of recommended questions (~0.41%) in emails were accurate enough to probably lead the recipient to answer.**\n",
    "* For the moment, we can not rely on school/group memberships, because only a tiny portion of the users have used them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Problem with the current System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current system, emails containing recommended questions are sent to professionals on a daily basis by default. \n",
    "\n",
    "The possible frequencies that a professional can choose from are:\n",
    "* Immediate\n",
    "* Daily\n",
    "* Weekly\n",
    "* Turn off all notifications.\n",
    "\n",
    "The 'daily' option is problematic. It is extremely difficult to to maintain a good quality of recommendations when the frequency is as high as 'Daily'. **We thus end up with a huge number of emails being sent daily with poor-quality recommendations. This can cause the professional to start ignoring emails and ultimately not returning to the site.**\n",
    "\n",
    "In addition, having poor-quality recommendations increases the chance that the professional will choose to turn off all notifications, which is not desirable.\n",
    "\n",
    "<span style=\"color: blue; font-weight: bold;\">Quick Solution proposal: </span> Maintain good-quality recommendations by removing the 'Daily' option, and only keeping the 'Immediate' & 'Weekly' options.\n",
    "\n",
    "Another *future* solution would be to leave it up to the system to decide when to email each professional depending on the interaction of the professional with the site.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic concepts and techniques used in the Recommender System <a class=\"anchor\" id=\"concepts\"></a>\n",
    "The recommender system works in two \"modes\":\n",
    "* **Professional-to-Questions**: Recommend top K questions to a particular professional (needed for the professionals who choose a fixed frequency like 'Weekly' option )\n",
    "* **Question-to-Professionals**: Recommend top K professionals most likely to answer a particular question. (needed for the professional who choose the 'Immediate' option)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Exploration-Exploitation Dilemma in Recommendations:\n",
    "\n",
    "![slots](https://i.imgur.com/pFO04zu.jpg?3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recommender system's job is not that simple. If a recommender system keeps suggesting the same items to the same users, then in some cases, questions about fairness might be raised, in other cases, users might get bored getting the same type of content. In the case of Question-Answering platforms like CareerVillage, potential interests (other than the ones already expressed by the professional through tags) might be ignored and users might stop coming to the platform.\n",
    "\n",
    "A recommendation system must not only recommend relevant questions to the professionals, **Occasionally, it should also introduce them to potentially new types of questions that might interest them**. It has to deal with the cold-start problem, where very little information about he professional is known.\n",
    "\n",
    "In the ML litterature, finding the right tradeoff between these two components is called the **Exploration-Exploitation problem**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Epsilon-Greedy Algorithm ( in a nutshell )\n",
    "\n",
    "To tackle the Exploration-Exploitation problem, a popular algorithm called **'Epsilon-Greedy'** is used.\n",
    "\n",
    "> It works by setting an Epsilon threshold, which represents the probability of 'Exploitation' .\n",
    "> \n",
    "> A random number N between 0.0 and 1.0 is generated,\n",
    "> \n",
    "> if N < Epsilon\n",
    "> \n",
    ">     Exploit by searching similar questions based on the past\n",
    "> \n",
    "> else\n",
    "> \n",
    ">     Explore new questions\n",
    "\n",
    "**The Epsilon-Greedy Algorithm is simple, easy to implement and does not need heavy computation, making it a great solution for the problem at hand. **\n",
    "\n",
    "*( More details on the inner-workings in a later section )*\n",
    "\n",
    "*Note: normaly Epsilon is used for exploration, in this implementation I used it for exploitation, but the idea is the same*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA: Latent Semantic Analysis (in a nutshell)\n",
    "\n",
    "Latent Semantic Analysis is a **simple**, yet **powerful** technique in Natural Language Processing. It captures the latent (hidden) topics of a corpus of text and represents each document by a vector of k dimensions, each pointing to one latent topic.\n",
    "\n",
    "To do this, LSA relies on a robust mathematical technique called SVD (Singular-Value Decomposition), which factorizes a real matrix to a product of 3 matrices. ([More on LSA and SVD](#links))\n",
    "\n",
    "\n",
    "<span style=\"color: red; font-weight: bold;\">Takeaway:</span> **Each question will be represented by a vector of length k. comparing the questions will be as easy as performing a cosine similarity between the vectors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing is paramount ! <a class=\"anchor\" id=\"preproc\"></a>\n",
    "\n",
    "\n",
    "<div style=\"border: solid 1px blue; padding: 5px;\"><h4><center><span style=\"color: red;\">If we let Garbage In, we get Garbage Out ! (GIGO)</span><center></h4></div>\n",
    "\n",
    "<br/>\n",
    "The most important data type in this project is Text (questions, tags ...). Unfortunately, if left unpreprocessed, it becomes extremely hard to extract useful information from it.\n",
    "\n",
    "This section's goal, is to prepare the data by simplifying it and removing any noise that migh get in the way between us and the True Information that we want to extract.\n",
    "\n",
    "This simple preprocessing can be easily done online in production, doesn't require a lot of computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Tags:\n",
    "For some reason, there are many tags which are not used in any question (and they are also not followed by any user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1865 useless tags were found and dropped.\n"
     ]
    }
   ],
   "source": [
    "# Drop tags that are not used in any question and not followed by any user (it will clean a lot of useless stuff)\n",
    "useless_tags = tags[~tags.index.isin(tag_questions['tag_id'].unique())]\n",
    "useless_tags = tags[ (tags.index.isin(useless_tags.index.values)) & (~tags.index.isin(tag_users['tag_id'].values)) ]\n",
    "tags = tags.drop(useless_tags.index)\n",
    "\n",
    "print(f'- {len(useless_tags)} useless tags were found and dropped.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make the following transformations to the tags:\n",
    "* make all tags lowercase.\n",
    "* create a new 'processed' column to hold the processed version of each tag\n",
    "* remove any special characters from the text.\n",
    "* correct some short words (yrs -> years)\n",
    "* lemmatize the tags ( eg. 'wolves' -> 'wolf' )\n",
    "* remove tags without any meaning that are just numbers, just preprositions, pronouns, stop-words ... ('where', 'and', 'the', '10', ...etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Tags were filtered out.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags_tag_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22750</th>\n",
       "      <td>optical-engineering</td>\n",
       "      <td>opticalengineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18468</th>\n",
       "      <td>git</td>\n",
       "      <td>git</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name           processed\n",
       "tags_tag_id                                         \n",
       "22750        optical-engineering  opticalengineering\n",
       "18468                        git                 git"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing Tags\n",
    "\n",
    "nbr_tags = len(tags)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# some common words / mistakes to filter out too\n",
    "stop_words.update(['want', 'go', 'like', 'aa', 'aaa', 'aaaaaaaaa', \n",
    "                   'good', 'best', 'would', 'get', 'as', 'th', 'k',\n",
    "                   'become', 'know', 'us'])\n",
    "special_characters = f'[{string.punctuation}]'\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "tags['name'] = tags['name'].str.lower()\n",
    "tags.fillna('', inplace=True)\n",
    "tags['processed'] = tags['name'].str.replace(special_characters, '')\n",
    "tags['processed'] = tags['processed'].str.replace('^\\d+$', '') # tags that are just numbers :-/\n",
    "tags['processed'] = tags['processed'].apply(lambda x: lm.lemmatize(x)) # avoid having plurals like 'career' and 'careers'\n",
    "tags['processed'] = tags['processed'].str.replace('^\\w$', '') # single letter tags :-/\n",
    "tags['processed'] = tags['processed'].str.replace(r'(\\d+)(yrs?)', r'\\1year') #\n",
    "tags['processed'] = tags['processed'].apply(lambda x: x if x not in stop_words else '')\n",
    "\n",
    "# Drop tags which are prepositions, pronouns, determiners, wh-adverbs (where, ...)\n",
    "tags_to_drop = []\n",
    "for i, t in tags['processed'].iteritems():\n",
    "    if len(t) > 0 and nltk.pos_tag([t])[0][1] in ['IN', 'PRP', 'WP$', 'PRP$', 'WP', 'DT', 'WRB']:\n",
    "        tags_to_drop.append(i)\n",
    "tag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\n",
    "tags = tags.drop(tags_to_drop)\n",
    "\n",
    "# Drop tags which are just numbers\n",
    "tags_to_drop = tags[tags['name'].str.contains('^\\d+$')].index\n",
    "tag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\n",
    "tags = tags.drop(tags_to_drop)\n",
    "\n",
    "# Drop tags which are just stop words ( after, the , with , ...)\n",
    "tags_to_drop = tags[tags['name'].isin(stop_words)].index\n",
    "tag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\n",
    "tags = tags.drop(tags_to_drop)\n",
    "\n",
    "print(f'{nbr_tags - len(tags)} Tags were filtered out.')\n",
    "tags.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color: red\">Result</span>**: We are now able to see that the following tags are the same: \"information-technology\", \"#informationtechnology\", \"#information-technology\", \"information-technology-\".\n",
    "\n",
    "A future task might be to explore how to add to this list the word \"IT\" (using word2vec), but the preprocessing is always necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Questions\n",
    "* We create a new column 'processed' containing both 'title' & 'body' text, and do the same transformations we did to tags ( remove special characters, lemmatize words and remove stop words ).\n",
    "* Create a new column 'count_answers'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions preprocessed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>processed</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5a267baa6f684f7cb98856f8e15820b4</th>\n",
       "      <td>Building credit is increasingly becoming an essential part to adulthood. What are the main things an individual must know when initially building credit?</td>\n",
       "      <td>#credit # #financial-planning #financial-services #commercial-banking</td>\n",
       "      <td>building credit increasingly becoming essential part adulthood main thing individual must initially building credit credit financialplanning financialservices commercialbanking</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                      title      ...      count_answers\n",
       "questions_id                                                                                                                                                                                     ...                   \n",
       "5a267baa6f684f7cb98856f8e15820b4  Building credit is increasingly becoming an essential part to adulthood. What are the main things an individual must know when initially building credit?      ...                  2\n",
       "\n",
       "[1 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions Cleaning\n",
    "\n",
    "questions['processed'] = questions['title'] + ' ' + questions['body']\n",
    "questions['processed'] = questions['processed'].str.lower()\n",
    "questions['processed'] = questions['processed'].str.replace('<.*?>', '') # remove html tags\n",
    "questions['processed'] = questions['processed'].str.replace('[-_]', '') # remove separators\n",
    "questions['processed'] = questions['processed'].str.replace(special_characters, ' ') # remove special characters\n",
    "\n",
    "questions['processed'] = questions['processed'].str.replace('\\d+\\s?yrs?', ' years') # single letter tags :-/\n",
    "\n",
    "def lem_question(q):\n",
    "    return \" \".join([lm.lemmatize(w) for w in q.split() if w not in stop_words])\n",
    "questions['processed'] = questions['processed'].apply(lem_question)\n",
    "\n",
    "questions['processed'] = questions['processed'].str.replace(r'(\\d+)($|\\s+)', r'\\2') # remove numbers which are not part of words\n",
    "questions['processed'] = questions['processed'].str.replace(r'(\\d+)([th]|k)', r'\\2') # remove numbers from before th and k\n",
    "\n",
    "\n",
    "# Function to preprocess new questions\n",
    "# TODO: update function to do like above\n",
    "def preprocess_question(q):\n",
    "    q = q.lower()\n",
    "    q = re.sub(\"<.*?>\", \"\", q)\n",
    "    q = re.sub(\"[-_]\", \"\", q)\n",
    "    q = re.sub(\"\\d+\", \"\", q)\n",
    "    q = q.translate(q.maketrans('', '', string.punctuation))\n",
    "    q = \" \".join([lm.lemmatize(t) for t in q.split()])\n",
    "    return q\n",
    "\n",
    "cnt_answers = answers.groupby('question_id').count()[['body']].rename(columns={'body': 'count_answers'})\n",
    "questions = questions.join(cnt_answers)\n",
    "questions['count_answers'] = questions['count_answers'].fillna(0)\n",
    "questions['count_answers'] = questions['count_answers'].astype(int)\n",
    "\n",
    "print('Questions preprocessed.')\n",
    "questions.sample(1)[['title', 'body', 'processed', 'count_answers']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Professionals\n",
    "* **Count Answers:** Create a new column 'count_answers' for professionals\n",
    "* **Cleaning the headlines**\n",
    "* **Follow Tags ?**: This is just a handy column I added to differentiate after between Pros who do and don't when evaluating the recommender\n",
    "* **Last Answer Date**: We will rely also on this new column to know if the professional is active or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting Answers ...\n",
      "Cleaning Headlines ...\n",
      "Creating \"follow_tags\" column ...\n",
      "Creating \"last_answer_date\" column ... \n",
      "Professionals preprocessed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>industry</th>\n",
       "      <th>headline</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>count_answers</th>\n",
       "      <th>follow_tags</th>\n",
       "      <th>last_answer_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionals_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88c2c86eb1154c749e8b3ccec92135c1</th>\n",
       "      <td>Orlando, Florida</td>\n",
       "      <td>Writing and Editing</td>\n",
       "      <td>copy editor at walt disney world</td>\n",
       "      <td>2017-05-05 17:57:01</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e80e8a6ff31a4262913635e9b026da69</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Primary/Secondary</td>\n",
       "      <td>guidance counselor &amp; student affairs coordinator at united international private school</td>\n",
       "      <td>2018-06-17 07:12:28</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148ef8986734096992a29084a2ebbe1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Individual and Family Services</td>\n",
       "      <td>life vocation advisor</td>\n",
       "      <td>2018-12-19 19:57:15</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-12-22 01:09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              location         ...            last_answer_date\n",
       "professionals_id                                               ...                            \n",
       "88c2c86eb1154c749e8b3ccec92135c1      Orlando, Florida         ...                         NaT\n",
       "e80e8a6ff31a4262913635e9b026da69  United Arab Emirates         ...                         NaT\n",
       "2148ef8986734096992a29084a2ebbe1         United States         ...         2018-12-22 01:09:00\n",
       "\n",
       "[3 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Count Answers\n",
    "print('Counting Answers ...')\n",
    "pro_answers_count = answers.groupby('author_id').count()[['question_id']].rename(columns={'question_id': 'count_answers'})\n",
    "professionals = professionals.join(pro_answers_count)\n",
    "professionals['count_answers'] = professionals['count_answers'].fillna(0)\n",
    "professionals['count_answers'] = professionals['count_answers'].astype(int)\n",
    "\n",
    "\n",
    "# Cleaning the headlines\n",
    "print('Cleaning Headlines ...')\n",
    "professionals['headline'] = professionals['headline'].fillna('')\n",
    "professionals['headline'] = professionals['headline'].str.lower()\n",
    "professionals['headline'] = professionals['headline'].str.replace('--|hello|hello!|hellofresh', '')\n",
    "\n",
    "# Check if follow tags or not\n",
    "print('Creating \"follow_tags\" column ...')\n",
    "professionals['follow_tags'] = False\n",
    "followers = list(tag_users['user_id'].unique())\n",
    "professionals.loc[professionals.index.isin(followers), 'follow_tags'] = True\n",
    "\n",
    "# Create Last Answer Date Column\n",
    "print('Creating \"last_answer_date\" column ... ')\n",
    "professionals = professionals.join(answers[['author_id', 'date_added']].groupby('author_id').max().rename(columns={'date_added': 'last_answer_date'}))\n",
    "\n",
    "\n",
    "print('Professionals preprocessed')\n",
    "professionals.sample(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Modeling !\n",
    "\n",
    "Now that we have pre-processed our data, we are ready for the modeling part.\n",
    "\n",
    "The modeling steps are as follows:\n",
    "\n",
    "* **Apply TF-IDF on the hole question corpus.**\n",
    "* **Apply SVD to reduce the dimensionality of the vectors.**\n",
    "* **Construct a Questions Similarity Matrix using The Cosine Similarity function.**\n",
    "\n",
    "After some experimentation, I chose the number of topics ( new dimensionality of question vectors ) to be 1100 ( values between 900~1100 are ok ).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the Model ...\n",
      " (1/3) TF-IDF matrix shape:  (23931, 18761)\n",
      " (2/3) Shape after Dimensionality Reduction: (23931, 1100)\n",
      " (3/3) Similarity Matrix Shape (23931, 23931) \n",
      "\n",
      "1.11 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words,)\n",
    "\n",
    "NUM_TOPICS = 1100\n",
    "def build_model(qs , nbr_topics=NUM_TOPICS):\n",
    "    print('Building the Model ...')\n",
    "    # TF-IDF Transformation\n",
    "\n",
    "    qs_tfidf = tfidf_vectorizer.fit_transform(qs['processed'])\n",
    "    terms = tfidf_vectorizer.get_feature_names()\n",
    "    print(' (1/3) TF-IDF matrix shape: ', qs_tfidf.shape)\n",
    "\n",
    "    # Dimensionality Reduction with SVD\n",
    "    model = TruncatedSVD(n_components=nbr_topics)\n",
    "    transformer_model = model.fit(qs_tfidf)\n",
    "    qs_transformed = transformer_model.transform(qs_tfidf)\n",
    "    print(' (2/3) Shape after Dimensionality Reduction:', qs_transformed.shape)\n",
    "\n",
    "    # Construct Similarity Matrix\n",
    "    sim_mat = cosine_similarity(qs_transformed, qs_transformed)\n",
    "    print(' (3/3) Similarity Matrix Shape', sim_mat.shape, '\\n')\n",
    "    return transformer_model, qs_transformed, sim_mat\n",
    "\n",
    "transformer_model, Qs_transformed, Qs_sim_matrix = build_model(questions)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'{(end-start)/60:.2f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">Notes on production:</span>\n",
    "* *Here, we use the totality of the question corpus when constructing the Similarity Matrix, in practice though, the similarity matrix will only be constructed with relatively recent questions ( last 1 or 2 years ), since old questions will not be of any use. Its construction only takes ~ 40 seconds for a ~ 24k x 24k matrix (pretty quick).*\n",
    "* *When in production, the Similarity Matrix & Questions Transformed Matrix must be updated on regular basis, depending on the traffic.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Recommendations Engine <a class=\"anchor\" id=\"implementation\"></a>\n",
    "\n",
    "In this section, we will build the recommendations engine from scratch using only the techniques previously talked about. Each sub-section will deal with a specific sub-problem.\n",
    "\n",
    "There are two main data structures we will work with:\n",
    "* **The Transformed Questions Matrix**: a Matrix where each row represents a single question encoded in a K dimensional vector\n",
    "* **The Similarity Matrix**: a NxN Matrix (where N is the number of questions) rating the similarity between all pair of questions on a scale of 0 ~ 1.\n",
    "\n",
    "Note that the recommender prioritizes **quality over quantity**. So, when asked for N recommendations, it will return the best k recommendations, where $k \\leq N$. The reason for this, is that the cost of bad recommendations can be high. We don't want users to get bad recommendations and ignore our future emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Professional-to-Questions Mode:\n",
    "In this mode, three types of professionals can be distinguished:\n",
    "* **Hot**: The professional has posted at least one answer. But if no answer is posted for a defined period ( in code I set the variable min_date_for_answers=400 days ) then professional will be treated as Cold.\n",
    "* **Cold**: The professional has never posted an answer, but follows some tags.\n",
    "* **Freezing**: The professional never posted an answer and doesn't follow any tags.\n",
    "\n",
    "When recommending K questions, each iteration can be either **Exploitation** or **Exploration**\n",
    "\n",
    "**How to deal with the 'Freezing' professional ?**\n",
    "\n",
    "The 'Freezing' professional has most probably registered recently, and doesn't follow any tags. We don't know much about him, the recommendations are more like 'suggestions' with the goal of taking him to the higher categories. \n",
    "\n",
    "We can suggest:\n",
    "* **Exploit:** session-based recommendations which recommend questions similar to questions already visited / upvoted or commented by the professional\n",
    "* **Explore:** popular questions on the platform and newly created ones.\n",
    "\n",
    "( session-based recommendations are only feasible in production, so in this implementation we stick with exploration for this type of users )\n",
    "\n",
    "**How to deal with the 'Cold' professional ?**\n",
    "\n",
    "Unlike the 'Freezing' professional, the 'Cold' one follows one more tags. This important hint must be fully exploited as followed:\n",
    "* **Exploit:** find relatively recent questions from the tags followed.\n",
    "* **Explore:** find tags similar to the followed tags and do the same. This is possible because of the simple *pre-processing of tags*.\n",
    "\n",
    "**How to deal with the 'Hot' professional ?**\n",
    "\n",
    "This type of professional has already expressed interest in one or more questions.\n",
    "* **Exploit:** suggest a similar question to one of the previously answered questions. To choose the answered question that will be the basis, we score all the questions and choose one question randomly based on the scores, which act as a probability distribution.\n",
    "* **Explore:** suggest most recent & similar questions from the tags followed as follows:\n",
    "    * Select the n most recent questions from each followed tag.\n",
    "    * from all those questions, select one the question which is most similar to one of the answered ones.\n",
    "\n",
    "<span style=\"color: red\">The Exploration/Exploitation approach has the advantage of not letting many questions unanswered by recommending often, and not over-focusing on the answered ones.</span>\n",
    "\n",
    "### Calculating the Exploit Threshold and Scoring Questions (for the 'Hot' professional):\n",
    "\n",
    "Unlike the the two other types of professionals, the optimal Exploit Threshold for the 'Hot' professional is dynamic and changes from a professional to another. Some professionals have only answered one question, while others have answered many. Some professionals have answers which date to a relatively long time, while others have just recently answered a few. **Taking these parameters into consideration affects positively the quality of the recommendations**.\n",
    "\n",
    "* We want our recommender to prioritize questions similar to questions recently answered by the professional\n",
    "* We also don't want to completely ignore older questions.\n",
    "\n",
    "### Question-Scoring Formula:\n",
    "The following formula scores the questions answered by the Hot professional while capturing the first note above:\n",
    "\n",
    "$$ score(x) = \\frac{log (\\frac{x}{\\epsilon})}{log (\\frac{1}{\\epsilon})} $$\n",
    "where:\n",
    "- x is the number of days elapsed between the date question was answered and today\n",
    "- $\\epsilon$ is the maximum number of days after which we no longer consider the question to be relevant ( now it is set to 370 but can be changed with the variable \"eps\", see code below )\n",
    "\n",
    "The formula gives a score between 0~1 where 1 means that the question is very relevant and should be used as a reference.\n",
    "\n",
    "Below is the values-table of the formula (credits to [this online grapher](https://www.desmos.com/calculator)). The formula \"rewards\" questions that are recent ( x is small ). And as x gets smaller, the score drops drown in a logarithmic fashion until it interesects with the x axis exactly at the value $\\epsilon$.\n",
    "\n",
    "![question_scoring_formula_table](https://i.imgur.com/HiHiQfA.png)\n",
    "\n",
    "### Exploit-Threshold Formula:\n",
    "\n",
    "After the (answered) questions get scored, the Exploit Threshold is calculated as follows:\n",
    "\n",
    "$$ threshold = log (\\sqrt{x} + 1) \\cdot \\alpha +  \\epsilon $$\n",
    "where:\n",
    "- x is the number of recently answered questions ( considering here only number of answers which have scores > 0 ).\n",
    "- $\\alpha$ controls the exploitation intensity (1.35 in the implementation). Acceptable values range between 1.0 for low exploitation and 1.7 for high exploitation.\n",
    "- $\\epsilon$ is an **optional** small value term (0.1 on the implementation) added if all answered questions are old ( meaning, that if x = 0, we still give a very small probability to $\\epsilon$ for exploitation, see the implementation below ).\n",
    "\n",
    "Below is values-table of the formula. The formula give a \"bigger\" exploit-threshold as more questions answered increase. It increases in a logarithmic fashion. ( there is a 1.35 in the left of the function in the value table but I couldn't get it to be visible)\n",
    "\n",
    "![threshold_formula_table](https://i.imgur.com/SqXgM5T.png)\n",
    "\n",
    "Below is the implementation of the two formulas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_question_answered(days_elapsed_after_answer):\n",
    "    eps = 370\n",
    "    score = np.log10(days_elapsed_after_answer*(1/eps)) / (np.log10(1/eps))\n",
    "    score = 0.001 if score < 0 else score # questions that got a score lower than 0 are still given a very low score\n",
    "    return score\n",
    "\n",
    "def calculate_exploit_threshold(answered_question_scores, nbr_recommendations, alpha=1.35):\n",
    "    nbr_questions_answered = len([s for s in answered_question_scores if s > 0])\n",
    "    eps = 0.1 if nbr_questions_answered == 0 else 0\n",
    "    return np.log10(np.sqrt(nbr_questions_answered) + 1) * alpha + eps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next snippet of code builds the recommendation engine using two main functions:**\n",
    "* **get_similar_questions**: returns similar questions to the one given using the similarity matrix ( the parameter \"similarity_threshold\" controls what similar means, I set it by default to be 0.4 as I found that value to work well for most cases ) .\n",
    "* **recommend_questions_to_professional**: given a professional ID, returns top K recommended questions.\n",
    "\n",
    "The debug variable below, if set to True,  makes exploration / exploitation decisions visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current date as the last day of the data\n",
    "def set_today(d_str):\n",
    "    d = pd.to_datetime(d_str)\n",
    "    \n",
    "    min_for_questions = d - np.timedelta64(600, 'D') # used for the Freezing professional to select the latest questions and for the cold to select the latest questions in followed and suggested tags\n",
    "    min_for_answers = d - np.timedelta64(400, 'D')   # used for hot professional to select his last answers. if no answers in this period, Hot professional will be treated as Cold\n",
    "    return d, min_for_questions, min_for_answers\n",
    "\n",
    "today, min_date_for_questions, min_date_for_answers = set_today('2019-01-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "*( Feel free to check the code below collapsed )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def choose_random_answered_question(question_score_dic):\n",
    "    random_key = choices(list(question_score_dic.keys()), list(question_score_dic.values()))[0]\n",
    "    return (random_key, question_score_dic[random_key])\n",
    "\n",
    "\n",
    "def choose_random_followed_tag(pro_id):\n",
    "    followed_tags = tag_users[tag_users['user_id'] == pro_id]\n",
    "    return followed_tags.sample(1)['tag_id'].values[0]\n",
    "\n",
    "def get_similar_questions(qid, nbr_questions=10, except_questions_ids=[], prioritize=False, similarity_threshold=0.4):\n",
    "    recommendations = pd.DataFrame([])\n",
    "\n",
    "    #print(len(except_questions_ids))\n",
    "    #print()\n",
    "    q_dists_row = list(Qs_sim_matrix[questions.index.get_loc(qid)])\n",
    "    for eq_id in except_questions_ids:\n",
    "        #print('removing ', eq_id)\n",
    "        #print(len(q_dists_row), questions.index.get_loc(eq_id))\n",
    "        q_dists_row[questions.index.get_loc(eq_id)] = -1\n",
    "    q_dists_row = pd.Series(q_dists_row).sort_values(ascending=False)[:100]\n",
    "    q_dists_row = q_dists_row[1:]\n",
    "\n",
    "    if not prioritize:\n",
    "        q_dists_row = q_dists_row[:nbr_questions]\n",
    "        for i, d in q_dists_row.iteritems():\n",
    "            qid = questions.index.values[i]\n",
    "            recommendations = recommendations.append(questions.loc[qid])\n",
    "    else:\n",
    "        qid_to_score = {}\n",
    "        for i, d in q_dists_row.iteritems():\n",
    "            qid = questions.index.values[i]\n",
    "            if d > similarity_threshold:\n",
    "                #print(qid)\n",
    "                q_added = questions.loc[qid, 'date_added']\n",
    "                days_elapsed = (today - q_added) / np.timedelta64(1, 'D')\n",
    "                qid_to_score[qid] = d * days_elapsed\n",
    "        qid_scores = sorted(qid_to_score.items(), key=lambda x: x[1])[:nbr_questions]\n",
    "        for qid, score in qid_scores:\n",
    "            print(q_dists_row[questions.index.get_loc(qid)], qid_to_score[qid]) if debug else None\n",
    "            recommendations = recommendations.append(questions.loc[qid])\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "\n",
    "def recommend_questions_to_professional(pro_id, nbr_recommendations=10, silent=False, alpha=1.35):\n",
    "    print('Professional ID:', pro_id ) if not silent else None\n",
    "\n",
    "    # tags followed\n",
    "    tags_followed = tag_users[tag_users['user_id'] == pro_id]['tag_id']\n",
    "    tags_followed = tags[tags.index.isin(tags_followed)]\n",
    "    print('Followed Tags: ', tags_followed['name'].values)  if not silent else None\n",
    "\n",
    "    # Number of answered questions\n",
    "    cnt_pro_answers = professionals.loc[pro_id, 'count_answers']\n",
    "    if cnt_pro_answers > 0:\n",
    "        pros_answers = answers[(answers['author_id'] == pro_id) & (answers['date_added'] < min_date_for_answers)]\n",
    "        cnt_pro_answers = len(pros_answers)\n",
    "\n",
    "    # Type of Start\n",
    "    cold_start = (cnt_pro_answers == 0)\n",
    "    freezing_start = (cold_start and len(tags_followed) == 0 )\n",
    "\n",
    "    n = 3 # Nbr of questions per tag\n",
    "    recommendations = pd.DataFrame([])\n",
    "\n",
    "\n",
    "    # Freezing Start\n",
    "    if freezing_start:\n",
    "        print('Freezing ...')  if not silent else None\n",
    "        recommendations = recommendations.append(questions[questions['date_added'] > min_date_for_questions].sample(10))\n",
    "\n",
    "    # Cold Start\n",
    "    elif cold_start:\n",
    "        print('Cold', cnt_pro_answers)  if not silent else None\n",
    "\n",
    "        qids_from_followed_tags  = tag_questions[tag_questions['tag_id'].isin(tags_followed.index.values)]['question_id'].values\n",
    "        qids_from_followed_tags  = list(questions[(questions.index.isin(qids_from_followed_tags))   & (questions['date_added'] > min_date_for_questions)].sort_values('date_added', ascending=False).index.values)\n",
    "\n",
    "        tags_suggested = tags[tags['processed'].isin(tags_followed['processed'].values)]\n",
    "        tags_suggested = tags_suggested[~tags_suggested.index.isin(tags_followed.index.values)]\n",
    "        print('Suggested Tags: ', tags_suggested['name'].values)  if not silent else None\n",
    "        suggested_tags_available = len(tags_suggested) > 0\n",
    "        # If there are suggested tags, we do explore on them while exploiting on the followed tags\n",
    "        if suggested_tags_available:\n",
    "            qids_from_suggested_tags = tag_questions[tag_questions['tag_id'].isin(tags_suggested.index.values)]['question_id'].values\n",
    "            qids_from_suggested_tags = list(questions[(questions.index.isin(qids_from_followed_tags))  & (questions['date_added'] > min_date_for_questions)].sort_values('date_added', ascending=False).index.values)\n",
    "            exploit_threshold = .6\n",
    "        # If no suggested tags are available, we just exploit on the followed tags\n",
    "        else:\n",
    "            exploit_threshold = 1\n",
    "\n",
    "\n",
    "        print('Exploit Threshold: ', exploit_threshold) if debug else None\n",
    "        for i in range(1, nbr_recommendations+1):\n",
    "            if np.random.rand() < exploit_threshold and len(qids_from_followed_tags) > 0:\n",
    "                # Exploit followed tags\n",
    "                print(f'{i}- Exploit followed tags') if debug else None\n",
    "                random_index = choice(qids_from_followed_tags)\n",
    "                q = questions.loc[random_index]\n",
    "                recommendations = recommendations.append(q)\n",
    "                qids_from_followed_tags.remove(random_index)\n",
    "            elif suggested_tags_available and len(qids_from_suggested_tags) > 0:\n",
    "                # Suggest from suggested tags\n",
    "                print(f'{i}- Explore suggested tags') if debug else None\n",
    "                random_index = choice(qids_from_suggested_tags)\n",
    "                q = questions.loc[random_index]\n",
    "                recommendations = recommendations.append(q)\n",
    "                qids_from_suggested_tags.remove(random_index)\n",
    "            else:\n",
    "                # no more questions from the pool\n",
    "                pass\n",
    "\n",
    "    # Hot Start\n",
    "    else:\n",
    "        \n",
    "        questions_answered_ids = list(pros_answers['question_id'].unique())\n",
    "        questions_answered = questions[questions.index.isin(questions_answered_ids)].sort_values('date_added', ascending=False)\n",
    "        questions_answered_locs = []\n",
    "        for qid in questions_answered_ids:\n",
    "            questions_answered_locs.append(questions.index.get_loc(qid))\n",
    "\n",
    "        print('Hot, Answered Questions: ', cnt_pro_answers)  if not silent else None\n",
    "        #print(questions_answered_locs)\n",
    "        display(questions_answered[['date_added', 'title', 'body', 'count_answers']])  if not silent else None\n",
    "        \n",
    "        # calculate answered questions scores\n",
    "        q_scores = {}\n",
    "        for i, q in questions_answered.iterrows():\n",
    "            answer_post_date = pros_answers[pros_answers['question_id'] == i]['date_added'].values[0]\n",
    "            days_elapsed_after_answer = (today - answer_post_date)/np.timedelta64(1, 'D')\n",
    "            q_scores[i] = calculate_score_question_answered(days_elapsed_after_answer)\n",
    "        print('Question-Scores: ', q_scores) if debug else None\n",
    "\n",
    "        # calculate exploit_threshold\n",
    "        exploit_threshold = calculate_exploit_threshold(list(q_scores.values()), nbr_recommendations, alpha=alpha)\n",
    "        print('Exploit Threshold:', exploit_threshold) if debug else None\n",
    "        except_qs = []\n",
    "        except_qs += questions_answered_ids\n",
    "        for i in range(nbr_recommendations):\n",
    "\n",
    "            if np.random.rand() < exploit_threshold:\n",
    "                # Exploit\n",
    "                random_q_score = choose_random_answered_question(q_scores)\n",
    "                print('\\nExploit Question', random_q_score) if debug else None\n",
    "                recommendations = recommendations.append(get_similar_questions(random_q_score[0], nbr_questions=1, except_questions_ids=except_qs, prioritize=True))\n",
    "            else:\n",
    "                # Explore\n",
    "                \n",
    "                # Get Latest n questions from all followed tags\n",
    "                n = 5\n",
    "                latest_questions = pd.DataFrame([])\n",
    "                for tid in tags_followed.index.values:\n",
    "                    qids = tag_questions[tag_questions['tag_id'] == tid]['question_id'].values\n",
    "                    tag_qs = questions[questions.index.isin(qids)]\n",
    "                    tag_qs = tag_qs[~tag_qs.index.isin(except_qs)]\n",
    "                    if len(tag_qs) > 0:\n",
    "                        tag_qs = tag_qs.sort_values('date_added', ascending=False)\n",
    "                        latest_questions = latest_questions.append(tag_qs.head(n))\n",
    "                #display(latest_questions)\n",
    "                \n",
    "                # Select the most similar one to the ones answered using the similarity matrix\n",
    "                best_question_id = 0\n",
    "                best_distance = float('-inf')\n",
    "                for qid, r in latest_questions.iterrows():\n",
    "                    qloc = questions.index.get_loc(qid)\n",
    "                    for aqloc in questions_answered_locs:\n",
    "                        d = Qs_sim_matrix[qloc, aqloc]\n",
    "                        if best_question_id == 0 or d > best_distance:\n",
    "                            best_question_id = qid\n",
    "                            best_distance = d\n",
    "\n",
    "                print('\\nExplore Tags', best_question_id, best_distance) if debug else None\n",
    "                if best_question_id != 0:\n",
    "                    recommendations = recommendations.append(questions.loc[best_question_id])\n",
    "            except_qs = list(recommendations.index.values)\n",
    "            except_qs += questions_answered_ids\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the recommender Part 1: standard random cases\n",
    "\n",
    "Here I'll let the recommender run on two randomly chosen professionals ( cold & Hot ).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional ID: 58a39fde2cdb4036a4e414624afcc0cc\n",
      "Followed Tags:  ['programming' 'electronics' 'web-development' 'theology'\n",
      " 'religious-institutions']\n",
      "Hot, Answered Questions:  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0c1e1323f1fe482cbbb1c417b17eae86</th>\n",
       "      <td>2017-02-13 00:13:43</td>\n",
       "      <td>What are the prerequisites to become a professor at a college?</td>\n",
       "      <td>I am studying Information Systems Technology and am planning on becoming a teacher some day. #teaching #professor #information-technology #university-teaching</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a96547de4f844e328f9902ed8f02acee</th>\n",
       "      <td>2017-02-12 19:39:11</td>\n",
       "      <td>What is the difference between an internship and a volunteer job?</td>\n",
       "      <td>I am a high school student completing my sophomore year and looking for a summer job.  Is it better to search for internship opportunities or volunteer opportunities since I have no work experienc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f9759393a694b85915ccf2cc853551e</th>\n",
       "      <td>2016-12-31 01:05:24</td>\n",
       "      <td>How can I improve my algorithm thinking?</td>\n",
       "      <td>I struggle trying to create simple algorithms. For instance, I would spend almost an entire day trying to figure out how to print an inverse right triangle with asterisks in my computer programmin...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_added      ...      count_answers\n",
       "questions_id                                              ...                   \n",
       "0c1e1323f1fe482cbbb1c417b17eae86 2017-02-13 00:13:43      ...                  4\n",
       "a96547de4f844e328f9902ed8f02acee 2017-02-12 19:39:11      ...                  2\n",
       "8f9759393a694b85915ccf2cc853551e 2016-12-31 01:05:24      ...                  4\n",
       "\n",
       "[3 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192293843820415295a4520db1ab8705</th>\n",
       "      <td>2018-10-30 14:06:48</td>\n",
       "      <td>Do professor cared about you being in class on time?</td>\n",
       "      <td>#professor #college #college-applications #college-major</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8454fbcf86f74d61989500ecf8a317bc</th>\n",
       "      <td>2018-08-28 21:29:02</td>\n",
       "      <td>How do I get internships in college?</td>\n",
       "      <td>#intern #internships #jobs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdf9c7cdcf184f6b9bbb18f40e0b70d9</th>\n",
       "      <td>2018-09-28 18:21:01</td>\n",
       "      <td>What should I do if my professor does not tolerate opposing thoughts?</td>\n",
       "      <td>#professor #college #discussion #tolerance #differentbeliefs</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cafb893daae445c19e982570a5cb2faf</th>\n",
       "      <td>2019-01-14 11:12:02</td>\n",
       "      <td>What does a computer programmer need?</td>\n",
       "      <td>#computer-hardware #technology #programming #technology #computer-science</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a90e3162b854760ab9d57abfe01afc1</th>\n",
       "      <td>2019-01-08 20:44:43</td>\n",
       "      <td>What allowed you to pursue in the field of technology?</td>\n",
       "      <td>#technology #computer #tech #programming #computer-science</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9e5df4f537843a385f3c3918e90ea6a</th>\n",
       "      <td>2018-06-15 01:24:34</td>\n",
       "      <td>Best colleges for computer programming?</td>\n",
       "      <td>#computer-science #computer-programming #computers #major #college #college-major #programming\\r\\n\\r\\nThings you can consider for this specific question...\\r\\n\\r\\nWhat colleges are highly ranked f...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98e25dbbb267450a801bd9ff77fb4827</th>\n",
       "      <td>2018-08-29 22:42:50</td>\n",
       "      <td>When becoming a college professor, is it more beneficial to start at a 4-year or transfer from a 2-year?</td>\n",
       "      <td>I want to know if it would be better for me to go to a 4-year college right off the bat when wanting to become a professor so I can familiarize myself when professors there who can help me. Or tra...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa9b180d4af44d47a553bad67601adaf</th>\n",
       "      <td>2019-01-14 11:13:36</td>\n",
       "      <td>What is the Employment Outlook for computer programmers?</td>\n",
       "      <td>#computer #computer-science #programming #technology #computer-programming</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db2d9fafb5564fa7b9f8dd7a5e593300</th>\n",
       "      <td>2019-01-22 14:58:37</td>\n",
       "      <td>What should I major if I want to work in cyber security?</td>\n",
       "      <td>#cyber-security #computer-science #technology #programming</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783d39c9311948f196652bfa434566fb</th>\n",
       "      <td>2017-09-01 02:23:40</td>\n",
       "      <td>How can I maintain good relationships with my professors once I go to college?</td>\n",
       "      <td>My teachers often advise me that it is important to get to know your professors in university, and I was wondering how I can do this.\\r\\n\\r\\n#professor  #positivity</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_added      ...      count_answers\n",
       "192293843820415295a4520db1ab8705 2018-10-30 14:06:48      ...                1.0\n",
       "8454fbcf86f74d61989500ecf8a317bc 2018-08-28 21:29:02      ...                1.0\n",
       "fdf9c7cdcf184f6b9bbb18f40e0b70d9 2018-09-28 18:21:01      ...                1.0\n",
       "cafb893daae445c19e982570a5cb2faf 2019-01-14 11:12:02      ...                1.0\n",
       "2a90e3162b854760ab9d57abfe01afc1 2019-01-08 20:44:43      ...                3.0\n",
       "d9e5df4f537843a385f3c3918e90ea6a 2018-06-15 01:24:34      ...                2.0\n",
       "98e25dbbb267450a801bd9ff77fb4827 2018-08-29 22:42:50      ...                2.0\n",
       "fa9b180d4af44d47a553bad67601adaf 2019-01-14 11:13:36      ...                1.0\n",
       "db2d9fafb5564fa7b9f8dd7a5e593300 2019-01-22 14:58:37      ...                2.0\n",
       "783d39c9311948f196652bfa434566fb 2017-09-01 02:23:40      ...                1.0\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional ID: 7bee8361e07f428cab3008ee9ee899a5\n",
      "Followed Tags:  ['higher-education' '#health' '#psychology' '#volunteer' '#well-being']\n",
      "Cold 0\n",
      "Suggested Tags:  ['psychology' 'health' 'volunteer' 'volunteers' 'highereducation'\n",
      " '#highereducation' 'psych-ology' 'psychology-' 'psychology#' 'wellbeing']\n",
      "Recommendations: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d70f64bf8ab44f5591398e62105be9c2</th>\n",
       "      <td>2017-10-08 19:35:43</td>\n",
       "      <td>What would be the best choice of high school courses to take to get ready to study orthodontics?</td>\n",
       "      <td>Trying to prepare for my future! #orthodontist #orthodontics #higher-education #college-major #career-planning</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32226212111f4917a83b34371b9beabf</th>\n",
       "      <td>2018-06-15 01:45:23</td>\n",
       "      <td>How much do college professors get paid?</td>\n",
       "      <td>I'm a CareerVillage staff member and I'm posting this because we know that many young people are looking for the answer to this question. This is among the most popular questions searched by youth...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2aa0d08731fa4f80bdd4cb3ccc6a0561</th>\n",
       "      <td>2018-04-24 18:39:50</td>\n",
       "      <td>Why are PsyD programs so under-funded?</td>\n",
       "      <td>I'm upset that even as a doctorate student I won't be funded #college #higher-education #doctorate-degree #finance</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31c2fc40011845fb8c6b06f7a142e8d3</th>\n",
       "      <td>2017-10-31 11:26:10</td>\n",
       "      <td>When is the online registration for the RRB SSE exam going to open?</td>\n",
       "      <td>#RRBExam ##india #higher-education</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2e7869caf494b5e9722e5ec35bff99b</th>\n",
       "      <td>2018-01-20 02:00:57</td>\n",
       "      <td>What is it like to teach English at the high school and college level?</td>\n",
       "      <td>My goal is to become an English teacher. I was planning on pursuing high school but someone suggested college. Since I haven't been to college yet I don't know what teachers are like there. Hearin...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a0236d19ce8841f58899749acb949b6b</th>\n",
       "      <td>2018-01-14 05:55:36</td>\n",
       "      <td>What skills are educators must acquire?</td>\n",
       "      <td>My major is Education but I am a little confused about what kind of skills I must acquire. #higher-education</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6b7ac2e46359406184bc35e88725a566</th>\n",
       "      <td>2018-01-17 03:59:45</td>\n",
       "      <td>What’s the most sufficient way to get a doctorate in Chemistry?</td>\n",
       "      <td>If there are opportunities to gain a doctorate without so many “filler” classes. #doctorate-degree  #chemistry  #higher-education #college</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8ec2f158cbb242bb802a3c44bbdccafa</th>\n",
       "      <td>2017-10-10 15:46:42</td>\n",
       "      <td>What level of education do you need to become an architect?</td>\n",
       "      <td>#architecture #architect #higher-education #architecture-and-planning</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5e3d8552466a43e5b5a3ecebc19283cc</th>\n",
       "      <td>2017-09-01 02:23:11</td>\n",
       "      <td>How can I maximize my education and opportunities in college and apply them to life after college&gt;</td>\n",
       "      <td>#college #real-world #opportunities #higher-education</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7ac79600bbb44109bc70241fd85d5b6e</th>\n",
       "      <td>2018-08-28 17:14:05</td>\n",
       "      <td>What are the chances of getting recruited and playing a collegiate sport?</td>\n",
       "      <td>I have been running track almost my whole life. I am somewhat good nationally and exceptional at my school district. I have done well in the past but this year I performed badly. #career-choice #h...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_added      ...      count_answers\n",
       "d70f64bf8ab44f5591398e62105be9c2 2017-10-08 19:35:43      ...                3.0\n",
       "32226212111f4917a83b34371b9beabf 2018-06-15 01:45:23      ...                5.0\n",
       "2aa0d08731fa4f80bdd4cb3ccc6a0561 2018-04-24 18:39:50      ...                1.0\n",
       "31c2fc40011845fb8c6b06f7a142e8d3 2017-10-31 11:26:10      ...                1.0\n",
       "d2e7869caf494b5e9722e5ec35bff99b 2018-01-20 02:00:57      ...                2.0\n",
       "a0236d19ce8841f58899749acb949b6b 2018-01-14 05:55:36      ...                2.0\n",
       "6b7ac2e46359406184bc35e88725a566 2018-01-17 03:59:45      ...                3.0\n",
       "8ec2f158cbb242bb802a3c44bbdccafa 2017-10-10 15:46:42      ...                2.0\n",
       "5e3d8552466a43e5b5a3ecebc19283cc 2017-09-01 02:23:11      ...                4.0\n",
       "7ac79600bbb44109bc70241fd85d5b6e 2018-08-28 17:14:05      ...                3.0\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Hot Professional\n",
    "random_hot_pro_id = professionals[(professionals['count_answers'] > 2) & (professionals['count_answers'] < 5)].sample(1).index.values[0]\n",
    "\n",
    "# Random Cold Professional ( check if he follows some tag )\n",
    "random_cold_pro_id = professionals[(professionals['count_answers'] == 0) & (professionals['follow_tags'] == True)].sample(1).index.values[0]\n",
    "\n",
    "\n",
    "#for random_pro_id in [random_hot_pro_id, random_cold_pro_id]:\n",
    "for random_pro_id in [random_hot_pro_id, random_cold_pro_id]:\n",
    "    recs = recommend_questions_to_professional(random_pro_id, nbr_recommendations=10)\n",
    "    print('Recommendations: ')\n",
    "    display(recs[['date_added', 'title', 'body', 'count_answers']]) if len(recs) > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Testing the recommender Part 2: Difficult Case **\n",
    "\n",
    "This is the case of a professional who follows 'cooking' and 'computer-games', but has answered a question about 'journalism' and 'scholarships'. We can see that the system balances nicely between the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional ID: fbd6566ddf36402abeb031c088096ae4\n",
      "Followed Tags:  ['cooking' 'computer-games']\n",
      "Hot, Answered Questions:  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83ee084ef5d546f5b16b66cf2b4acf6c</th>\n",
       "      <td>2015-09-17 17:46:08</td>\n",
       "      <td>Is being a newscaster hard?</td>\n",
       "      <td>I am thinking about becoming a newscaster for my career in life. #journalism #news #newscaster</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6c5ae0b4f56488c9f7351b8b6c63f51</th>\n",
       "      <td>2015-08-19 20:45:27</td>\n",
       "      <td>How do you get a full-ride scholarship to a university?</td>\n",
       "      <td>I'm a junior in highschool and I want to know how getting a scholarship works? #money</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18f8485afa0e4f559197beb9ee0ca195</th>\n",
       "      <td>2015-08-18 12:59:25</td>\n",
       "      <td>How do i discover my passion?</td>\n",
       "      <td>I usually hear many people complaining of the kind of work they do, even saying they are only working just for a living and given an option, they will not even think twice, they will grab the new ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_added      ...      count_answers\n",
       "questions_id                                              ...                   \n",
       "83ee084ef5d546f5b16b66cf2b4acf6c 2015-09-17 17:46:08      ...                  4\n",
       "f6c5ae0b4f56488c9f7351b8b6c63f51 2015-08-19 20:45:27      ...                  3\n",
       "18f8485afa0e4f559197beb9ee0ca195 2015-08-18 12:59:25      ...                  8\n",
       "\n",
       "[3 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59184dc0d4b24f1fa92c3f07bce183a5</th>\n",
       "      <td>2019-01-26 00:56:16</td>\n",
       "      <td>What is it like to really be a chef in a professional kitchen or even a bakery owner . What do you do daily ? Do you really enjoy what it is that your doing ? Have you ever had any regrets about c...</td>\n",
       "      <td>#chef #career #baker #advice #cooking</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6cea3ac361e2428283bf4ecee282dbcc</th>\n",
       "      <td>2018-10-22 01:39:30</td>\n",
       "      <td>I am interested in journalism, are there a lot of opportunities for this major?</td>\n",
       "      <td>#journalism #college-major #college #professional #photojournalism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8bb567b6a29a458db7ee9dafad0354d6</th>\n",
       "      <td>2018-07-06 19:56:09</td>\n",
       "      <td>Is there certain schools for Journalism?</td>\n",
       "      <td>#college-choice #college #colleges #journalism</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcfac02347ac472fa1356619eb4cba58</th>\n",
       "      <td>2018-01-22 17:09:05</td>\n",
       "      <td>I want a career related to a video games. What do I major in?</td>\n",
       "      <td>I'm a junior in high school. I'm in my schools tech academy and i'm very unsure of my what I want to major in.I love video games and would want a job related to them. What are skills I need for vi...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2de48f91c8b34a95b250d99cf3f8d840</th>\n",
       "      <td>2018-10-17 23:57:46</td>\n",
       "      <td>What's the best scholarship website?</td>\n",
       "      <td>I am a mother going back to school and looking for the best scholarships #scholarship</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_added      ...      count_answers\n",
       "59184dc0d4b24f1fa92c3f07bce183a5 2019-01-26 00:56:16      ...                1.0\n",
       "6cea3ac361e2428283bf4ecee282dbcc 2018-10-22 01:39:30      ...                1.0\n",
       "8bb567b6a29a458db7ee9dafad0354d6 2018-07-06 19:56:09      ...                0.0\n",
       "bcfac02347ac472fa1356619eb4cba58 2018-01-22 17:09:05      ...                3.0\n",
       "2de48f91c8b34a95b250d99cf3f8d840 2018-10-17 23:57:46      ...                1.0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_hot_pro_id = 'fbd6566ddf36402abeb031c088096ae4'\n",
    "recs = recommend_questions_to_professional(random_hot_pro_id, nbr_recommendations=10)\n",
    "print('Recommendations:')\n",
    "display(recs[['date_added', 'title', 'body', 'count_answers']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Question-to-Professionals mode:\n",
    "\n",
    "Given a question, recommend the top K professionals to answer. This mode is used for the 'Immediate' professionals.\n",
    "\n",
    "The overall approach taken is straightforward: recommend professionals who answered similar questions to the one given. \n",
    "\n",
    "The 'Hot' professionals have the biggest probability to answer and are recommended, since a **key requirement of the recommender is to get a good quality answer as soon as possible.**\n",
    "\n",
    "\n",
    "### Is a professional active ?\n",
    "It is important to know the answer to this question. Maybe the professional has answered numerous questions similar to the query but is no longer active on the platform ! So out of N candidates, we will select our k recommended ones based on their activity.\n",
    "\n",
    "\n",
    "Here, we select the top k candidates using two metrics:\n",
    "* How active they are: we determine this by using the 'last_answer_date' column, if the professional has answered a question in the last n days he gets priority (n = 60 by default in implementation) .\n",
    "* If the number candidates is still smaller than the required k, we add candidates based on the number of similar questions they answered even if they weren't active in the last n days. ( of course they have all answered similar questions, but in the first step, we prioritized the active ones, in the second step, which is optional, we fill in the missing places with professionals who answered most similar questions ). \n",
    "\n",
    "You can check the small piece of code below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_professionals_for_question(qid, nbr_recommendations=10, inactivity_period=60):\n",
    "    #print(len(questions), len(answers))\n",
    "    similar_questions = get_similar_questions(qid, nbr_questions=10, except_questions_ids=[], prioritize=False)\n",
    "    #display(similar_questions)\n",
    "    answer_author_ids = answers[answers['question_id'].isin(similar_questions.index.values)]['author_id'].values\n",
    "    answer_author_ids = pd.Series(answer_author_ids).value_counts()\n",
    "    \n",
    "    # Step 1: Check how active the the candidates are\n",
    "    min_last_answer_date = today - np.timedelta64(inactivity_period, 'D')\n",
    "    candidates = professionals[(professionals.index.isin(answer_author_ids.index.values)) & (professionals['last_answer_date'] > min_last_answer_date)].sort_values('last_answer_date', ascending=False)\n",
    "    answer_author_ids = answer_author_ids.drop(candidates.index)\n",
    "    \n",
    "    # Step 2: if number of candidates is still smaller than nbr_recommendations, fill in with other authors based on how many similar questions they answered.\n",
    "    if len(candidates) < nbr_recommendations:\n",
    "        others = answer_author_ids.head(nbr_recommendations-len(candidates)).index.values\n",
    "        candidates = candidates.append(professionals[professionals.index.isin(others)])\n",
    "    return candidates[:nbr_recommendations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Question:  daa938bd24e84d9ea4787742dadeb3ac 2016-05-23 21:25:06\n",
      "How do you work yourself up to become a creative director in Advertising in terms of majors and minors?\n",
      "I am not completely sure what I want to minor in in college #advertising\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>industry</th>\n",
       "      <th>headline</th>\n",
       "      <th>count_answers</th>\n",
       "      <th>last_answer_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionals_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5fb15f468af546bbbf7861b0025b947d</th>\n",
       "      <td>Nipomo, California</td>\n",
       "      <td>Hospital and Health Care</td>\n",
       "      <td>principal at gravell insights, llc</td>\n",
       "      <td>78</td>\n",
       "      <td>2019-01-20 03:02:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc28056163a8447686e5691f4c1475b0</th>\n",
       "      <td>Southfield, Michigan</td>\n",
       "      <td>Broadcast Media</td>\n",
       "      <td>commercial producer at wwjtv / cw50 detroit wkbd</td>\n",
       "      <td>93</td>\n",
       "      <td>2018-12-07 02:38:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857c406b7a0b40cbbed53ce95e51bc81</th>\n",
       "      <td>New York, New York</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>director global vaccines public affairs at pfizer</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-05 20:55:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49f38e98c0424e339c71dbd90eeca351</th>\n",
       "      <td>Zürich, Switzerland</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>territory manager, central region for norton by symantec</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-05-19 06:46:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09242796b4fe4983a11fcee35f50d325</th>\n",
       "      <td>California, California</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>digital marketing &amp; project management for ecommerce platforms</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-07-11 02:08:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3ec3179cf5404696a1d322c22395e50c</th>\n",
       "      <td>India</td>\n",
       "      <td>Consumer Goods</td>\n",
       "      <td>senior retail marketing manager</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-07-08 06:41:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2307e2205da4759a5a1c27ac988808a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>consumer insights manager</td>\n",
       "      <td>30</td>\n",
       "      <td>2018-02-02 04:04:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8ba7c732fe9741f08aa62736592e1ba8</th>\n",
       "      <td>Dearborn, Michigan</td>\n",
       "      <td>Graphic Design, Advertising and Management</td>\n",
       "      <td>revive.</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-05 17:07:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                location         ...            last_answer_date\n",
       "professionals_id                                                 ...                            \n",
       "5fb15f468af546bbbf7861b0025b947d      Nipomo, California         ...         2019-01-20 03:02:57\n",
       "dc28056163a8447686e5691f4c1475b0    Southfield, Michigan         ...         2018-12-07 02:38:35\n",
       "857c406b7a0b40cbbed53ce95e51bc81      New York, New York         ...         2018-12-05 20:55:07\n",
       "49f38e98c0424e339c71dbd90eeca351     Zürich, Switzerland         ...         2016-05-19 06:46:53\n",
       "09242796b4fe4983a11fcee35f50d325  California, California         ...         2017-07-11 02:08:39\n",
       "3ec3179cf5404696a1d322c22395e50c                   India         ...         2016-07-08 06:41:33\n",
       "d2307e2205da4759a5a1c27ac988808a                     NaN         ...         2018-02-02 04:04:07\n",
       "8ba7c732fe9741f08aa62736592e1ba8      Dearborn, Michigan         ...         2017-05-05 17:07:14\n",
       "\n",
       "[8 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_question_index = choice(questions.index.values)\n",
    "\n",
    "print('Random Question: ', random_question_index,  questions.loc[random_question_index]['date_added'])\n",
    "print(questions.loc[random_question_index]['title'])\n",
    "print(questions.loc[random_question_index]['body'])\n",
    "recommend_professionals_for_question(random_question_index, nbr_recommendations=8)[['location', 'industry', 'headline', 'count_answers', 'last_answer_date']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions in production:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tag Suggestions for a new question:\n",
    "It is very important to control tags, and use existing ones when possible. The following function suggests tags for a new question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Analyze processed question and extracts implicit tags ( eg. 'computer science' => 'computerscience')\n",
    "def get_tag_suggestions(q_p):\n",
    "    #q_p = preprocess_question(q)\n",
    "    #print(q_p)\n",
    "    q_tokens = nltk.word_tokenize(q_p)\n",
    "    q_tokens_cpy = q_tokens.copy()\n",
    "    \n",
    "    qp_tagged = nltk.pos_tag(q_tokens)\n",
    "    important = []\n",
    "    for t,pos in qp_tagged:\n",
    "        if t not in stop_words and pos == 'NN' and len(tags[tags['processed'] == t]) > 0 :\n",
    "            i = q_tokens.index(t)\n",
    "            #print(len(q_p), t, i)\n",
    "            poses_before_after = []\n",
    "            if i > 0:\n",
    "                poses_before_after.append(nltk.pos_tag([q_tokens[i-1]])[0])\n",
    "            if i < (len(q_tokens)-1):\n",
    "                poses_before_after.append(nltk.pos_tag([q_tokens[i+1]])[0])\n",
    "            for i, bf in enumerate(poses_before_after):\n",
    "                #print(t, bf)\n",
    "                if bf[1] in ['NN', 'NNS', 'JJ', 'JJR', 'VBG']:\n",
    "                    s = f'{t}{bf[0]}' if i == 1 else f'{bf[0]}{t}'\n",
    "                    important.append(s)\n",
    "            q_tokens.remove(t)\n",
    "    important = set(important)\n",
    "    for i in set(important):\n",
    "        if i not in tags['processed'].values or i in q_tokens_cpy:\n",
    "            important.remove(i)\n",
    "    #print(len(important),important)\n",
    "    \n",
    "    return tags[tags['processed'].isin(important)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example: \n",
    "\n",
    "The following example illustrates how many tags this question is related to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  I am a student in computer science and I want to be a data scientist but I dont know how to study machine learning and artificial intelligence. Can anyone give some advice ?\n",
      "\n",
      "Tag Suggestions: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags_tag_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>computer-science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29420</th>\n",
       "      <td>computerscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18791</th>\n",
       "      <td>machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29702</th>\n",
       "      <td>computer_science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34595</th>\n",
       "      <td>artificialintelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37542</th>\n",
       "      <td>#artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32065</th>\n",
       "      <td>#computerscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31605</th>\n",
       "      <td>#computer-science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31759</th>\n",
       "      <td>computer-science-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35849</th>\n",
       "      <td>#machinelearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31195</th>\n",
       "      <td>machine-learning-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name\n",
       "tags_tag_id                          \n",
       "461                  computer-science\n",
       "1846          artificial-intelligence\n",
       "29420                 computerscience\n",
       "18791                machine-learning\n",
       "29702                computer_science\n",
       "34595          artificialintelligence\n",
       "37542        #artificial-intelligence\n",
       "32065                #computerscience\n",
       "31605               #computer-science\n",
       "31759               computer-science-\n",
       "35849                #machinelearning\n",
       "31195               machine-learning-"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_question = 'I am a student in computer science and I want to be a data scientist but I dont know how to study machine learning and artificial intelligence. Can anyone give some advice ?' \n",
    "p_q = preprocess_question(new_question)\n",
    "suggestions = get_tag_suggestions(p_q)\n",
    "print('Question: ', new_question)\n",
    "print('\\nTag Suggestions: ')\n",
    "suggestions[['name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to add a new question to DB:\n",
    "\n",
    "When a new question enters a DB, it should be converted and added to our model.\n",
    "* The following function transforms the new question to a vector and adds it to the matrix\n",
    "* adds an entry ( one row and one column ) to the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Generate a random index for adding a question to DB\n",
    "def gen_test_index():\n",
    "    length = np.random.randint(10,15)\n",
    "    letters_digits = string.ascii_lowercase + string.digits\n",
    "    return ''.join(random.sample(letters_digits, length))\n",
    "\n",
    "\n",
    "def add_question_to_db(title, body):\n",
    "    global questions\n",
    "    global Qs_transformed\n",
    "    global Qs_sim_matrix\n",
    "    \n",
    "    q = title + ' ' + body\n",
    "    q_p = preprocess_question(q)\n",
    "    \n",
    "    tag_suggestions = get_tag_suggestions(q_p)\n",
    "    q_p = q_p + ' ' + ' '.join(tag_suggestions)\n",
    "    \n",
    "    print(q_p)  if debug else None\n",
    "    \n",
    "    author_id = 1 # special if for test ( doesn't exist in DB )\n",
    "    index = gen_test_index()\n",
    "    questions = questions.append(pd.Series({'author_id': author_id,'date_added': pd.to_datetime('now'), \n",
    "                                                  'title': title,\n",
    "                                                  'body': body, \n",
    "                                                  'processed': q_p, \n",
    "                                                  'count_answers': 0}, name=index))\n",
    "    print('Qs Transformed before', qs_transformed.shape) if debug else None\n",
    "    q_transformed = transformer_model.transform(tfidf_vectorizer.transform([q_p]))\n",
    "    Qs_transformed = np.append(Qs_transformed, [Qs_transformed[0]], axis=0)\n",
    "    print('Qs Transformed after', Qs_transformed.shape)  if debug else None\n",
    "    \n",
    "    sim_mat_shape = Qs_sim_matrix.shape\n",
    "    print('Similarity Matrix shape before', sim_mat_shape)  if debug else None\n",
    "    new_sims = cosine_similarity(Qs_transformed[-1].reshape(1,-1),Qs_transformed)[0]\n",
    "    print('new_sims', new_sims.shape)  if debug else None\n",
    "    Qs_sim_matrix = np.hstack((Qs_sim_matrix, np.zeros((sim_mat_shape[0], 1))))\n",
    "    Qs_sim_matrix = np.vstack((Qs_sim_matrix, np.zeros((sim_mat_shape[0]+1))))\n",
    "    Qs_sim_matrix[-1] = new_sims\n",
    "    Qs_sim_matrix[:, -1] = new_sims\n",
    "    print('Similarity Matrix shape before', sim_mat_shape)  if debug else None\n",
    "    print('Question Added to DB.')  if debug else None\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Recommender System using a Time Machine ! <a class=\"anchor\" id=\"eval\"></a>\n",
    "\n",
    "Recommender Systems are trickier to evaluate than - for example - a machine learning classifier. The reason is that the current recommender system influences the data that we have at hand ( that we are using for training and testing ).\n",
    "\n",
    "However, we can still get a idea about the performance of the model we're testing if we choose the good metrics and methodology for our project.\n",
    "\n",
    "\n",
    "We can distinguish between two types of evaluation: **Offline & Online Evaluation**.\n",
    "\n",
    "*The Offline Evaluation* is used before deploying the model, to check its accuracy on the existing data. However, this method is **NOT** enough.\n",
    "Usually, only it's only after the model is deployed, and A/B tests are that we can draw conclusions about the actual performance of our system. This second step is referred to as *Online Evaluation*\n",
    "\n",
    "<span style=\"color: purple\">Another important thing about having a fixed offline evaluation framework, even though it's not accurate, is that we can use it as basis evaluate multiple recommender systems, or to fine-tune parameters related to our model, and observe how the results change ( before pushing the changes to prod ) .</span>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Methodology\n",
    "\n",
    "For offline evaluation, I chose to use a real-world **Split Validation** method. It works as follows:\n",
    "\n",
    "* First, I extract a small amount of data ( the most recent ) for example the last 6 months (let's say October 2018 ~ November 2018), this will be the **Test Set**\n",
    "* The model is built using only the other part of the data ( the oldest ), this is the **Traning Set** .\n",
    "* Edit all data so that we can simulate exactly how the system was at that particular point in time : questions, answers and professionals that were added after the date ( July 2018 ) are removed.\n",
    "\n",
    "Now that the system looks exactly as  it was (let's say at October 2018), the tests occur weekly:\n",
    "- Each week, new questions, answers and professionals are added. \n",
    "- **Hide all answers that occured that week from the recommender.**\n",
    "- The recommender system makes predictions about:\n",
    "    * **the professionals who answered the questions: Given that a question \"Q\" was answered this week, use Question-to-Professionals mode and see if the recommendations generated for this question contain the professionals who actually answered the question. ( do that for all questions answered this week and each week of the test period )**\n",
    "    * **the questions that were answered by the professionals: Given that a professional \"P\" answered some question(s), use Professional-to-Questions mode and see if the recommendations generated for that professional contain the questions that the professional actually answered. ( do that for all professionals who posted answers this week and each week of the test period )**\n",
    "- The goal is to make as many accurate recommendations as possible. Meaning, send recommendations to professionals who actually answered the questions that week, or recommend the answered questions to the right professionals.\n",
    "- Note here, that the recommender can perform much better in production, because when evaluating it here, we don't account for potential answers coming as a result of the recommender itself.\n",
    "- The test system makes the following assumption: **if the model made accurate offline recommendations about the answered questions, it would do so for the unanswered ones in production.**\n",
    "\n",
    "\n",
    "The following code snippet builds our *\"Time Machine\"* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Backup\n",
    "questions_full = questions.copy()\n",
    "answers_full = answers.copy()\n",
    "professionals_full = professionals.copy()\n",
    "tag_users_full = tag_users.copy()\n",
    "tag_questions_full = tag_questions.copy()\n",
    "\n",
    "def run_time_machine(today_str):\n",
    "    global today\n",
    "    global min_date_for_questions\n",
    "    global min_date_for_answers\n",
    "    global professionals\n",
    "    global questions\n",
    "    global answers\n",
    "    global tag_users\n",
    "    global tag_questions\n",
    "    global tfidf_vectorizer\n",
    "    global transformer_model\n",
    "    global Qs_transformed\n",
    "    global Qs_sim_matrix\n",
    "\n",
    "    \n",
    "    first_date = pd.to_datetime('2012-01-01') \n",
    "\n",
    "    today, min_date_for_questions, min_date_for_answers = set_today(today_str)\n",
    "    print('Running Time Machine ....', 'Going to', today.strftime('%B %d %Y'), '................\\n')\n",
    "\n",
    "    professionals = professionals_full[professionals_full['date_joined'] < today].copy()\n",
    "    assert (professionals['date_joined'].max() < today), \"Professionals have date_joined > today !\"\n",
    "    questions = questions_full[(questions_full['date_added'] > first_date) & (questions_full['date_added'] < today)].copy()\n",
    "    answers = answers_full[(answers_full['date_added'] > first_date) & (answers_full['date_added'] < today) & (answers_full['question_id'].isin(questions.index.values))].copy()\n",
    "\n",
    "    #test_questions = questions_full[(questions_full['date_added'] > today) & (questions_full['count_answers'] > 0)].copy()\n",
    "    #test_answers   = answers_full[(answers_full['question_id'].isin(test_questions.index.values)) & (answers_full['author_id'].isin(professionals.index.values))].copy()\n",
    "    #print(len(test_questions), 'Test questions (with at least one answer)')\n",
    "    #print(len(test_answers), 'Answers were posted for the test questions (from professionals who joined before that date)')\n",
    "\n",
    "    cnt_answers = answers.groupby('question_id').count()[['body']].rename(columns={'body': 'count_answers'})\n",
    "    questions = questions.drop('count_answers', axis=1)\n",
    "    questions = questions.join(cnt_answers)\n",
    "    questions['count_answers'] = questions['count_answers'].fillna(0)\n",
    "    questions['count_answers'] = questions['count_answers'].astype(int)\n",
    "\n",
    "\n",
    "    cnt_answers = answers.groupby('author_id').count()[['question_id']].rename(columns={'question_id': 'count_answers'})\n",
    "    professionals = professionals.drop('count_answers', axis=1)\n",
    "    professionals = professionals.join(cnt_answers)\n",
    "    professionals['count_answers'] = professionals['count_answers'].fillna(0)\n",
    "    professionals['count_answers'] = professionals['count_answers'].astype(int)\n",
    "\n",
    "    # Create Last Answer Date Column\n",
    "    professionals = professionals.drop('last_answer_date', axis=1)\n",
    "    professionals = professionals.join(answers[['author_id', 'date_added']].groupby('author_id').max().rename(columns={'date_added': 'last_answer_date'}))\n",
    "\n",
    "\n",
    "    tag_users = tag_users_full[tag_users_full['user_id'].isin(professionals.index.values)].copy()\n",
    "    tag_questions = tag_questions_full[tag_questions_full['question_id'].isin(questions.index.values)].copy()\n",
    "\n",
    "    transformer_model, Qs_transformed, Qs_sim_matrix = build_model(questions)\n",
    "    gc.collect()\n",
    "    print('##################################\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this *\"Time Machine\"* is slow. This is because to simulate the exact state of the system at a particular date (each week) I rebuild the model each time ( I tried adding just what changed, but it was not better ). I chose a relatively short period for the test ( 2018-08-01 ~ 2018-08-22 ).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Date and End Date of the Simulation\n",
    "\n",
    "test_start_date = pd.to_datetime('2018-08-01')\n",
    "test_end_date = pd.to_datetime('2018-08-22')\n",
    "nbr_weeks = math.floor((test_end_date - test_start_date)/ np.timedelta64(1, 'W'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of the model:\n",
    "\n",
    "We can fine-tune the following parameters:\n",
    "* **Number of recommendations to generate each time**: 5 for Professional -> Questions Mode and 10 for Question -> Professionals Mode\n",
    "* **Number of days without answers to consider a professional not active ( for selection of professionals to answer a question )**: 60 days\n",
    "* **Exploitation Intensity ($\\alpha$)**: 1.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of recommendations to generate for each professional. ( for the other mode, Question->Professional, it's nbr_recs*2)\n",
    "nbr_recs_pro_to_qs = 5\n",
    "nbr_recs_q_to_pros = nbr_recs_pro_to_qs * 2\n",
    "\n",
    "# Exploitation Intensity ( 1.0 ~ 1.7 )\n",
    "alpha_arg=1.35\n",
    "\n",
    "# Number of days to consider professional as inactive\n",
    "inactivity_period_arg=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start First Simulation August 01, 2018 ---> August 22, 2018 ( 3  weeks ) \n",
      "\n",
      "\n",
      "-----------  Week 1  -----------\n",
      "Running Time Machine .... Going to August 08 2018 ................\n",
      "\n",
      "Building the Model ...\n",
      " (1/3) TF-IDF matrix shape:  (21304, 17795)\n",
      " (2/3) Shape after Dimensionality Reduction: (21304, 1100)\n",
      " (3/3) Similarity Matrix Shape (21304, 21304) \n",
      "\n",
      "##################################\n",
      "\n",
      "2018-08-01 00:00:00  ~  2018-08-08 00:00:00  - Number of answers:  276  - Number answered questions:  248  - Number authors:  123\n",
      "Making Predictions for the week's answered questions ...\n",
      "\n",
      "-----------  Week 2  -----------\n",
      "Running Time Machine .... Going to August 15 2018 ................\n",
      "\n",
      "Building the Model ...\n",
      " (1/3) TF-IDF matrix shape:  (21572, 17894)\n",
      " (2/3) Shape after Dimensionality Reduction: (21572, 1100)\n",
      " (3/3) Similarity Matrix Shape (21572, 21572) \n",
      "\n",
      "##################################\n",
      "\n",
      "2018-08-08 00:00:00  ~  2018-08-15 00:00:00  - Number of answers:  477  - Number answered questions:  384  - Number authors:  193\n",
      "Making Predictions for the week's answered questions ...\n",
      "\n",
      "-----------  Week 3  -----------\n",
      "Running Time Machine .... Going to August 22 2018 ................\n",
      "\n",
      "Building the Model ...\n",
      " (1/3) TF-IDF matrix shape:  (21952, 18054)\n",
      " (2/3) Shape after Dimensionality Reduction: (21952, 1100)\n",
      " (3/3) Similarity Matrix Shape (21952, 21952) \n",
      "\n",
      "##################################\n",
      "\n",
      "2018-08-15 00:00:00  ~  2018-08-22 00:00:00  - Number of answers:  758  - Number answered questions:  577  - Number authors:  258\n",
      "Making Predictions for the week's answered questions ...\n",
      "\n",
      "-------- End of Simulation (4.86 minutes) --------\n"
     ]
    }
   ],
   "source": [
    "## %%time\n",
    "\n",
    "print('Start First Simulation', test_start_date.strftime('%B %d, %Y'), '--->', test_end_date.strftime('%B %d, %Y'), '(', nbr_weeks, ' weeks )', '\\n')\n",
    "start = time.time()\n",
    "#run_time_machine(test_start_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "\n",
    "question_to_pros_recs = {}\n",
    "pro_to_questions_recs = {}\n",
    "\n",
    "nbr_accurate_q_to_pros = 0\n",
    "nbr_accurate_pro_to_qs = 0\n",
    "nbr_all_q_to_pros = 0\n",
    "nbr_all_pro_to_qs = 0\n",
    "\n",
    "\n",
    "correct_question_ids = set([])\n",
    "all_question_ids = set([])\n",
    "\n",
    "today = test_start_date\n",
    "for i in range(1, nbr_weeks+1):\n",
    "    print('\\n----------- ', 'Week', i, ' -----------')\n",
    "    d_old = today\n",
    "    run_time_machine((today + np.timedelta64(1, 'W')).strftime('%Y-%m-%d'))\n",
    "\n",
    "    week_questions= questions[(questions['date_added'] > d_old) & (questions['date_added'] < today)]\n",
    "    week_answers = answers[(answers['date_added'] > d_old) & (answers['date_added'] < today) & (answers['author_id'].isin(professionals.index.values))].copy()\n",
    "    \n",
    "    if len(week_answers) == 0:\n",
    "        continue\n",
    "    \n",
    "    target_questions = week_questions[week_questions.index.isin(week_answers)]\n",
    "    qs_answered_this_week = list(week_answers['question_id'].unique())\n",
    "    authors_this_week = week_answers['author_id'].unique()\n",
    "    all_question_ids.update(qs_answered_this_week)\n",
    "\n",
    "    print( d_old, ' ~ ', today, ' - Number of answers: ', len(week_answers), ' - Number answered questions: ', len(qs_answered_this_week), ' - Number authors: ', len(authors_this_week))\n",
    "    \n",
    "    # Hide answers from the system !!!\n",
    "    answers = answers.drop(week_answers.index)\n",
    "    for auth_id in authors_this_week:\n",
    "        professionals.at[auth_id, 'count_answers'] = len(answers[answers['author_id'] == auth_id])\n",
    "\n",
    "    # some tests to check if everything is ok\n",
    "    assert (len(answers[(answers['date_added'] < today) & (answers['date_added'] > d_old) & (answers['author_id'].isin(professionals.index.values)) ]) == 0), \"The answers of this week were not all removed\"\n",
    "    random_auth_id = authors_this_week[0]\n",
    "    assert (professionals.loc[random_auth_id, 'count_answers'] == len(answers[answers['author_id'] == random_auth_id])), \"Problem with count of answers for professional\"\n",
    "\n",
    "    print('Making Predictions for the week\\'s answered questions ...')\n",
    "    # Predict pros for questions that were answered ( Question->Pros )\n",
    "    for qid in qs_answered_this_week:\n",
    "        question_to_pros_recs[qid] = recommend_professionals_for_question(qid, nbr_recommendations=nbr_recs_q_to_pros, inactivity_period=inactivity_period_arg)\n",
    "        recommended_pro_ids = set(question_to_pros_recs[qid].index.values)\n",
    "        nbr_all_q_to_pros += len(recommended_pro_ids)\n",
    "        target_pro_ids = set(week_answers[week_answers['question_id'] == qid]['author_id'].unique())\n",
    "        union_len = len(target_pro_ids.union(recommended_pro_ids))\n",
    "        sum_len = len(recommended_pro_ids) + len(target_pro_ids)\n",
    "        if union_len < sum_len:\n",
    "            nbr_accurate_q_to_pros += (sum_len - union_len)\n",
    "            correct_question_ids.update([qid])\n",
    "            \n",
    "    # Predict questions for pros who answered ( Pro->Questions )\n",
    "    for auth_id in authors_this_week:\n",
    "        pro_to_questions_recs[auth_id] = recommend_questions_to_professional(auth_id, nbr_recommendations=nbr_recs_pro_to_qs, silent=True, alpha=alpha_arg)\n",
    "        recommended_question_ids = set(pro_to_questions_recs[auth_id].index.values)\n",
    "        nbr_all_pro_to_qs += len(recommended_question_ids)\n",
    "        target_question_ids = set(week_answers[week_answers['author_id'] == auth_id]['question_id'].unique())\n",
    "        union_len = len(target_question_ids.union(recommended_question_ids))\n",
    "        sum_len = len(recommended_question_ids) + len(target_question_ids)\n",
    "        if union_len < sum_len:\n",
    "            nbr_accurate_pro_to_qs += (sum_len - union_len)\n",
    "            correct_question_ids.update([e for e in recommended_question_ids if e in target_question_ids])\n",
    "    \n",
    "    #print('Number of Accurate Recommendations (Question -> Pros): ', nbr_accurate_q_to_pros)\n",
    "    #print('Number of Accurate Recommendations (Pro -> Questions): ', nbr_accurate_pro_to_qs)\n",
    "\n",
    "end = time.time()\n",
    "print(f'\\n-------- End of Simulation ({(end-start)/60:.2f} minutes) --------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics & Results of the Evaluation\n",
    "\n",
    "\n",
    "Two principal metrics are used:\n",
    "* **Proportion of answered questions got right**: meaning, out of all the questions that were answered, how many of them did we get right when making recommendations\n",
    "* **Proportion of accurate recommendations**: out of all recommendations made, how many did we get right\n",
    "\n",
    "Now, the proposed recommender system is compared to the legacy-one. Let's check the same metrics for recommendations made by the previous legacy-system in the same test period.\n",
    "\n",
    "*<span style=\"color: red;\">REMINDER:</span>* **This evaluation is actually not fair !** Because as mentioned before, the legacy recommender is actually influencing the answers we have at hand. **But ouf of curiosity**, we want to check how many accurate recommendations the proposed system is able to make, even without being deployed ! This must be taken into consideration when looking at the following numbers.\n",
    "\n",
    "Furthermore, many answers are just the product of users visiting the site \"organically\", and not the product of any recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the Test:\n",
      "- Percentage of Answered Questions that got accurate recommendations: 19.19% ( 219 out of 1141 questions  )\n",
      "\n",
      "- Percentage of accurate recommendations ( out of all sent ones ):\n",
      "\t- Question-to-Professionals Mode:  1.76%  ( 203 out of 11536 recommendations were accurate )\n",
      "\t- Professional-to-Questions Mode: 1.40%  ( 36 out of 2566 recommendations were accurate )\n"
     ]
    }
   ],
   "source": [
    "print('Results of the Test:')\n",
    "print(f\"- Percentage of Answered Questions that got accurate recommendations: {len(correct_question_ids)/len(all_question_ids)*100:.2f}%\", f'( {len(correct_question_ids)} out of {len(all_question_ids)} questions  )' )\n",
    "print('\\n- Percentage of accurate recommendations ( out of all sent ones ):')\n",
    "print(f'\\t- Question-to-Professionals Mode:  {(nbr_accurate_q_to_pros/nbr_all_q_to_pros)*100:.2f}% ',  f'( {nbr_accurate_q_to_pros} out of {nbr_all_q_to_pros} recommendations were accurate )')\n",
    "print(f'\\t- Professional-to-Questions Mode: {(nbr_accurate_pro_to_qs/nbr_all_pro_to_qs)*100:.2f}% ', f'( {nbr_accurate_pro_to_qs} out of {nbr_all_pro_to_qs} recommendations were accurate )')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The only True Evaluation\n",
    "\n",
    "The only True Evaluation is done **online** with **good A/B Tests**, and with **measuring the right metrics**. I list here some metrics that should be considered:\n",
    "* **Number of active professionals**: we decide that a professional is active at time t if he answered a question in the last n days ( n = 100 in implementation )\n",
    "* **Mean Time-to-First-Answer**: $\\frac{1}{nbr \\thinspace questions}\\sum_{q}^{questions}{nbr \\thinspace days \\thinspace between \\thinspace question \\thinspace q \\thinspace was \\thinspace posted \\thinspace and \\thinspace its \\thinspace first \\thinspace answer}$\n",
    "* **Number of accurate recommendations**\n",
    "* **Percentage of accurate recommendations**: Ratio $\\frac{Number \\thinspace of \\thinspace accurate \\thinspace recommendations}{Number \\thinspace of \\thinspace all \\thinspace recommendations}$. The higher the ratio, the better. It will also help avoid churning.\n",
    "\n",
    "Running A/B Tests on the parameters of the model will help to find the best combination of values that maximizes the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Future Explorations <a class=\"anchor\" id=\"future\"></a>\n",
    "\n",
    "The proposed system's strengths are **its effectiveness, ease of implementation and ease of maintainance in production.**\n",
    "It uses controlled randomness to encourage new users while keeping engaged professionals in the platform.\n",
    "\n",
    "The proposed system is designed to be very **resilient** when it comes to difficult cases like professionals with **various interests**. In addition to recommending questions based on semantic similarity, the proposed system also recommends relevant questions from tags, and from **tags which are textually similar to the followed ones** (eg. 'computer-science' and 'computerscience', 'information-technology' and 'informationtechnology' ) .\n",
    "\n",
    "Further, a basic framework for evaluating the system was proposed along with the most important metrics to measure.\n",
    "\n",
    "Some recommendations for future improvements:\n",
    "\n",
    "* **Meta-data based Recommendations:** \n",
    "\n",
    "It is possible to use valuable information obtained when users open a browsing session ( viewed and visited questions, ... ).\n",
    "\n",
    "* **Controlling Tags:**\n",
    "\n",
    "It is important to preprocess tags and prevent the students from using tags which already exist. A powerful model possibly based on Word2Vec, could be used to model the relationships and similarities between tags. For example, capturing the similarity between 'information-technology' and 'IT' would hugely boost the performance of the recommender.\n",
    "\n",
    "* **Controlling Typos**:\n",
    "\n",
    "Using a spell-checking engine like [Hunspell](https://pypi.org/project/hunspell/) would increase the quality of the data and help the engine make better recommendations\n",
    "\n",
    "* **Using the answers and comments in the model**:\n",
    "\n",
    "In this model, only the text of the questions was used when encoding the questions. Another model should be explored, where we also make use of the answers and comments of each question to encode the questions.\n",
    "\n",
    "* **Making use of upvotes**:\n",
    "\n",
    "Unfortunately, The data provided about upvotes (questions & answers) wasn't specific as to who upvoted what. If this data was available, it could be used to better understand the interests of both professionals and students, and thus making better predictions.\n",
    "\n",
    "* **Using other Exploration Techniques**:\n",
    "\n",
    "I decided to go with the $\\epsilon$ Greedy Algorithm for its simpleness and ease of use. Other algorithms can be further explored like \"Optismism in face of uncertainty\" and \"Probability Matching\" ([See Links for more](#links))\n",
    "\n",
    "* **Making use of serious Reinforcement Learning**\n",
    "\n",
    "Finally, after exploring the previous suggestions, a very insteresting project would be to to make use of RL techniques, where the recommender uses the feedback of its actions (recommendations) to update and improve its future behaviour (recommendations). [See Links for more](#links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>I hope that this Kernel was useful, and see you in the <a href=\"https://www.kaggle.com/hamzael1/kernels\" target=\"_blank\">next one</a> !</h4>\n",
    "\n",
    "*PS: upvotes & feedback are welcome !*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links to useful Ressources: <a class=\"anchor\" id=\"links\"></a>\n",
    "<h4>About Recommender systems</h4>\n",
    "* [A whole Coursera Specialization about Recommender Systems](https://www.coursera.org/specializations/recommender-systems)\n",
    "* [Recommender Systems in Practice](https://towardsdatascience.com/recommender-systems-in-practice-cef9033bb23a)\n",
    "* [An amazing Playlist of Stanford University Videos about Mining Datasets](https://www.youtube.com/watch?v=1JRrCEgiyHM&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV&index=42&t=0s)\n",
    "\n",
    "<h4>About Epsilon Greedy and Exploration/Exploitation</h4>\n",
    "* [The Multi-armed Bandit Problem](https://en.wikipedia.org/wiki/Multi-armed_bandit)\n",
    "* [A nice article About Epsilon-Greedy Algorithm](https://imaddabbura.github.io/post/epsilon_greedy_algorithm/)\n",
    "* [Some great slides about how to solve the Exploration/Exploitation dilemma](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/XX.pdf)\n",
    "\n",
    "<h4>About Latent Semantic Analysis and SVD</h4>\n",
    "* [A nice short video about LSA](https://www.youtube.com/watch?v=OvzJiur55vo)\n",
    "* [A great explanation of SVD by Professor Jure Leskovec](https://www.youtube.com/watch?v=P5mlg91as1c&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV&index=47)\n",
    "\n",
    "<h4>About Reinforcement Learning in Recommender Systems</h4>\n",
    "* [Reinforcement Learning for Recommender Systems: A Case Study on Youtube](https://www.youtube.com/watch?v=HEqQ2_1XRTs)\n",
    "* [Contextualized Bandits for Recommendation Systems](https://towardsdatascience.com/bandits-for-recommender-system-optimization-1d702662346e)\n",
    "* [Netflix using using Contextualized Bandits for personalizing the selection of artwork](https://medium.com/netflix-techblog/artwork-personalization-c589f074ad76)\n",
    "* [A Multi-Armed Bandit Framework for Recommendations at Netflix](https://www.youtube.com/watch?v=kY-BCNHd_dM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
