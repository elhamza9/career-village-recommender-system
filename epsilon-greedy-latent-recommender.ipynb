{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Epsilon-Greedy Latent Recommender</center></h1>\n",
    "\n",
    "<center>Hamza El Bouatmani on 14th April, 2019 </center>\n",
    "\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "<a href=\"https://www.careervillage.org/\" target=\"_blank\">CareerVillage.org</a> <span style=\"color: purple;\">is a cloud-based solution for career advice</span>. It provides a platform where students with career-related questions meet professionals from the industry who help them by answering their questions.\n",
    "\n",
    "The goal of <a href=\"https://www.kaggle.com/c/data-science-for-good-careervillage/overview\" target=\"_blank\">this competition</a>, is to develop a method to recommend relevant questions to the professionals who are most likely to answer them.\n",
    "\n",
    "In this notebook, I propose a solution that addresses the problem in an efficient manner using a probabilistic approach (Epsilon-Greedy) combined with an industry-proven *state-of-the-art technique (SVD)*. **This combination aims to balance between Exploration & Exploitation, targeting both the new and already-engaged professionals in an effective and efficient manner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "## Why do we need a Recommender ? Let's ask the Data !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/hamzael1/an-extensive-eda-for-careervillage\" target=\"_blank\">In a previous notebook</a> I have made a detailed Exploratory Data Analysis on the provided data. Here, I will be brief and focus on the most important points which relate to the problem at hand.\n",
    "\n",
    "*Note: some code snippets that are trivial are collapsed for better readability, feel free to expand them if you want to check the code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important numbers:\n",
      "\n",
      "There are:\n",
      "- 30971 Students.\t- 28152 Professionals.\n",
      "- 23931 Questions.\t- 51123 Answers.\n",
      "- 16269 Tags.\t\t- 14966 Comments.\n",
      "- 2706 Schools.\t\t- 49 Groups.\n",
      "\n",
      "Interesting statistics: \n",
      "- 96.57 % of the questions have at least 1 answer.\n",
      "\n",
      "- 97.31% of questions are tagged by at least 1 tag.\n",
      "- Mean of tags per question: 3.29 tags per question.\n",
      "\n",
      "- 90.91 % of the professionals follow at least 1 Tag (25594).\n",
      "- 14.88 % of the students follow at least 1 Tag (4608).\n",
      "\n",
      "- 96.93 % of questions were upvoted (23196).\n",
      "- 57.82 % of answers were upvoted (13837).\n",
      "\n",
      "- 63.88 % of the professionals have Zero answers (17983).\n",
      "- 0.41 % of recommended questions in emails were accurate (lead to professional answering the recommended question) (17576)\n",
      "\n",
      "- Only 0.04 % of the students are members of schools (1355).\n",
      "- Only 0.15 % of the professionals are members of schools (4283).\n",
      "\n",
      "- Only 0.01 % of the students are members of groups (311).\n",
      "- Only 0.03 % of the professionals are members of groups (727).\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import random\n",
    "from random import choice, choices\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Professionals Import\n",
    "\n",
    "professionals = pd.read_csv('../input/professionals.csv', index_col='professionals_id')\n",
    "professionals = professionals.rename(columns={'professionals_location': 'location', 'professionals_industry': 'industry', 'professionals_headline': 'headline', 'professionals_date_joined': 'date_joined'})\n",
    "professionals['headline'] = professionals['headline'].fillna('')\n",
    "professionals['industry'] = professionals['industry'].fillna('')\n",
    "\n",
    "# Students Import\n",
    "\n",
    "students = pd.read_csv('../input/students.csv', index_col='students_id')\n",
    "students = students.rename(columns={'students_location': 'location', 'students_date_joined': 'date_joined'})\n",
    "\n",
    "# Questions Import\n",
    "questions = pd.read_csv('../input/questions.csv', index_col='questions_id', parse_dates=['questions_date_added'], infer_datetime_format=True)\n",
    "questions = questions.rename(columns={'questions_author_id': 'author_id', 'questions_date_added': 'date_added', 'questions_title': 'title', 'questions_body': 'body', 'questions_processed':'processed'})\n",
    "\n",
    "# Answers Import\n",
    "answers = pd.read_csv('../input/answers.csv', index_col='answers_id', parse_dates=['answers_date_added'], infer_datetime_format=True)\n",
    "answers = answers.rename(columns={'answers_author_id':'author_id', 'answers_question_id': 'question_id', 'answers_date_added': 'date_added', 'answers_body': 'body'})\n",
    "\n",
    "# Tags Import\n",
    "tags = pd.read_csv('../input/tags.csv',)\n",
    "tags = tags.set_index('tags_tag_id')\n",
    "tags = tags.rename(columns={'tags_tag_name': 'name'})\n",
    "\n",
    "# Comments Import\n",
    "comments = pd.read_csv('../input/comments.csv', index_col='comments_id')\n",
    "comments = comments.rename(columns={'comments_author_id': 'author_id', 'comments_parent_content_id': 'parent_content_id', 'comments_date_added': 'date_added', 'comments_body': 'body' })\n",
    "\n",
    "\n",
    "# School Memberships\n",
    "school_memberships = pd.read_csv('../input/school_memberships.csv')\n",
    "school_memberships = school_memberships.rename(columns={'school_memberships_school_id': 'school_id', 'school_memberships_user_id': 'user_id'})\n",
    "\n",
    "# Groups Memberships\n",
    "group_memberships = pd.read_csv('../input/group_memberships.csv')\n",
    "group_memberships = group_memberships.rename(columns={'group_memberships_group_id': 'group_id', 'group_memberships_user_id': 'user_id'})\n",
    "\n",
    "\n",
    "#####################################################\n",
    "print('Important numbers:')\n",
    "print('\\nThere are:')\n",
    "print(f'- {len(students)} Students.', end=\"\\t\")\n",
    "print(f'- {len(professionals)} Professionals.')\n",
    "print(f'- {len(questions)} Questions.', end=\"\\t\")\n",
    "print(f'- {len(answers)} Answers.')\n",
    "print(f'- {len(tags)} Tags.', end=\"\\t\\t\")\n",
    "print(f'- {len(comments)} Comments.')\n",
    "print(f'- {school_memberships[\"school_id\"].nunique()} Schools.', end=\"\\t\\t\")\n",
    "print(f'- {len(pd.read_csv(\"../input/groups.csv\"))} Groups.')\n",
    "#####################################################\n",
    "\n",
    "# Questions-related stats\n",
    "tag_questions = pd.read_csv('../input/tag_questions.csv',)\n",
    "tag_questions = tag_questions.rename(columns={'tag_questions_tag_id': 'tag_id', 'tag_questions_question_id': 'question_id'})\n",
    "count_question_tags = tag_questions.groupby('question_id').count().rename(columns={'tag_id': 'count_tags'}).sort_values('count_tags', ascending=False)\n",
    "print('\\nInteresting statistics: ')\n",
    "print(f'- {(answers[\"question_id\"].nunique()/len(questions))*100:.2f} % of the questions have at least 1 answer.')\n",
    "print(f'\\n- {(len(count_question_tags)/len(questions))*100:.2f}% of questions are tagged by at least {count_question_tags[\"count_tags\"].tail(1).values[0]} tag.')\n",
    "print(f'- Mean of tags per question: {count_question_tags[\"count_tags\"].mean():.2f} tags per question.')\n",
    "\n",
    "tag_users = pd.read_csv('../input/tag_users.csv',)\n",
    "tag_users = tag_users.rename(columns={'tag_users_tag_id': 'tag_id', 'tag_users_user_id': 'user_id'})\n",
    "users_who_follow_tags = list(tag_users['user_id'].unique())\n",
    "nbr_pros_tags = len(professionals[professionals.index.isin(users_who_follow_tags)])\n",
    "nbr_students_tags = len(students[students.index.isin(users_who_follow_tags)])\n",
    "print(f'\\n- {(nbr_pros_tags / len(professionals))*100:.2f} % of the professionals follow at least 1 Tag ({nbr_pros_tags}).')\n",
    "print(f'- {(nbr_students_tags / len(students))*100:.2f} % of the students follow at least 1 Tag ({nbr_students_tags}).')\n",
    "\n",
    "question_scores = pd.read_csv('../input/question_scores.csv')\n",
    "nbr_questions_with_hearts = question_scores[question_scores['score'] > 0]['id'].nunique()\n",
    "print(f'\\n- {(nbr_questions_with_hearts/len(questions))*100:.2f} % of questions were upvoted ({nbr_questions_with_hearts}).')\n",
    "\n",
    "answer_scores = pd.read_csv('../input/answer_scores.csv')\n",
    "nbr_answers_with_hearts = answer_scores[answer_scores['score'] > 0]['id'].nunique()\n",
    "print(f'- {(nbr_answers_with_hearts/len(questions))*100:.2f} % of answers were upvoted ({nbr_answers_with_hearts}).')\n",
    "\n",
    "# Professionals who did not contribute\n",
    "nbr_pros_without_answers = len(professionals) - answers['author_id'].nunique()\n",
    "print(f'\\n- {(nbr_pros_without_answers/len(professionals))*100:.2f} % of the professionals have Zero answers ({nbr_pros_without_answers}).')\n",
    "\n",
    "# Number of accurate recommendations\n",
    "emails = pd.read_csv('../input/emails.csv')\n",
    "emails = emails.set_index('emails_id')\n",
    "emails = emails.rename(columns={'emails_recipient_id':'recipient_id', 'emails_date_sent': 'date_sent', 'emails_frequency_level': 'frequency_level'})\n",
    "#emails.sample(2)\n",
    "\n",
    "matches = pd.read_csv('../input/matches.csv')\n",
    "matches = matches.join(emails[['recipient_id', 'date_sent']], on='matches_email_id')\n",
    "\n",
    "matches = matches.rename(columns={'matches_question_id': 'question_id', 'matches_email_id': 'email_id'})\n",
    "\n",
    "matches['author_id'] = matches['recipient_id']\n",
    "m = answers.reset_index().merge(matches, on=['question_id', 'author_id']).set_index('answers_id')\n",
    "nbr_accurate_recommendations = len(m)\n",
    "matches = matches.drop('author_id', axis=1)\n",
    "print(f'- {(nbr_accurate_recommendations/len(matches))*100:.2f} % of recommended questions in emails were accurate (lead to professional answering the recommended question) ({nbr_accurate_recommendations})')\n",
    "\n",
    "\n",
    "# School/Group Related Stats\n",
    "\n",
    "def is_student(user_id):\n",
    "    if user_id in students.index.values:\n",
    "        return 1\n",
    "    elif user_id in professionals.index.values:\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError('User ID not student & not professional')\n",
    "\n",
    "school_memberships['is_student'] = school_memberships['user_id'].apply(is_student)\n",
    "school_memberships['is_student'] = school_memberships['is_student'].astype(int)\n",
    "count_students_professionals = school_memberships.groupby('is_student').count()[['school_id']].rename(columns={'school_id':'count'})\n",
    "print(f'\\n- Only {count_students_professionals.loc[1].values[0]/len(students):.2f} % of the students are members of schools ({count_students_professionals.loc[1].values[0]}).')\n",
    "print(f'- Only {count_students_professionals.loc[0].values[0]/len(professionals):.2f} % of the professionals are members of schools ({count_students_professionals.loc[0].values[0]}).')\n",
    "\n",
    "group_memberships['is_student'] = group_memberships['user_id'].apply(is_student)\n",
    "group_memberships['is_student'] = group_memberships['is_student'].astype(int)\n",
    "count_students_professionals = group_memberships.groupby('is_student').count()[['group_id']].rename(columns={'group_id':'count'})\n",
    "print(f'\\n- Only {count_students_professionals.loc[1].values[0]/len(students):.2f} % of the students are members of groups ({count_students_professionals.loc[1].values[0]}).')\n",
    "print(f'- Only {count_students_professionals.loc[0].values[0]/len(professionals):.2f} % of the professionals are members of groups ({count_students_professionals.loc[0].values[0]}).')\n",
    "\n",
    "del m\n",
    "del emails\n",
    "del matches\n",
    "del students\n",
    "del school_memberships\n",
    "del group_memberships\n",
    "del count_question_tags\n",
    "del users_who_follow_tags\n",
    "del nbr_pros_tags\n",
    "del nbr_students_tags\n",
    "del nbr_pros_without_answers\n",
    "del nbr_questions_with_hearts\n",
    "del count_students_professionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "* Tags are heavily used by students in questions.\n",
    "* Most professionals follow tags to find questions related to their expertise.\n",
    "* **A big portion of the professionals (~63%) hasn't answered any question yet.**\n",
    "* **Only a tiny proportion of recommended questions (~0.41%) in emails were accurate enough to probably lead the recipient to answer.**\n",
    "* For the moment, we can not rely on school/group memberships, because only a tiny portion of the users have used them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem with the current System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current system, emails containing recommended questions are sent to professionals on a daily basis by default. \n",
    "\n",
    "The possible frequencies that a professional can choose from are:\n",
    "* Immediate\n",
    "* Daily\n",
    "* Weekly\n",
    "\n",
    "The 'daily' option is problematic. It is extremely difficult to to maintain a good quality of recommendations when the frequency is as high as 'Daily'. **We thus end up with a huge number of emails being sent daily with poor-quality recommendations. This can cause the professional to start ignoring emails and ultimately not returning to the site.**\n",
    "\n",
    "<span style=\"color: blue; font-weight: bold;\">Quick Solution proposal: </span> Maintain good-quality recommendations by removing the 'Daily' option, and only keeping the 'Immediate' & 'Weekly' options.\n",
    "\n",
    "Another *future* solution would be to leave it up to the system to decide when to email each professional depending on the interaction of the professional with the site.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic techniques used in the Recommender System\n",
    "The recommender system works in two \"modes\":\n",
    "* **Professional-to-Questions**: Recommend top K questions to a particular professional (needed for the professionals who choose a fixed frequency like 'Weekly' option )\n",
    "* **Question-to-Professionals**: Recommend top K professionals most likely to answer a particular question. (needed for the professional who choose the 'Immediate' option)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Exploration-Exploitation Dilemma in Recommendations:\n",
    "\n",
    "![slots](https://i.imgur.com/pFO04zu.jpg?3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recommender system's job is not that simple. If a recommender system keeps suggesting the same items to the same users, then in some cases, questions about fairness might be raised, in other cases, users might get bored getting the same type of content. In the case of Question-Answering platforms like CareerVillage, potential interests (other than the ones already expressed by the professional through tags) might be ignored and users might stop coming to the platform.\n",
    "\n",
    "A recommendation system must not only recommend relevant questions to the professionals, **Occasionally, it should also introduce them to potentially new types of questions that might interest them**. It has to deal with the cold-start problem, where very little information about he professional is known.\n",
    "\n",
    "In the ML litterature, finding the right tradeoff between these two components is called the **Exploration-Exploitation problem**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Epsilon-Greedy Algorithm ( in a nutshell )\n",
    "\n",
    "To tackle the Exploration-Exploitation problem, a popular algorithm called **'Epsilon-Greedy'** is used.\n",
    "\n",
    "> It works by setting an Epsilon threshold, which represents the probability of 'Exploitation' .\n",
    "> \n",
    "> A random number N between 0.0 and 1.0 is generated,\n",
    "> \n",
    "> if N < Epsilon\n",
    "> \n",
    ">     Exploit by searching similar questions based on the past\n",
    "> \n",
    "> else\n",
    "> \n",
    ">     Explore new questions\n",
    "\n",
    "**The Epsilon-Greedy Algorithm is simple, easy to implement and does not need heavy computation, making it a great solution for the problem at hand. **\n",
    "\n",
    "*( More details on the inner-workings in a later section )*\n",
    "\n",
    "*Note: normaly Epsilon is used for exploration, in this implementation I used it for exploitation, but the idea is the same*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA: Latent Semantic Analysis (in a nutshell)\n",
    "\n",
    "Latent Semantic Analysis is a **simple**, yet **powerful** technique in Natural Language Processing. It captures the latent (hidden) topics of a corpus of text and represents each document by a vector of k dimensions, each pointing to one latent topic.\n",
    "\n",
    "To do this, LSA relies on a robust mathematical technique called SVD (Singular-Value Decomposition), which factorizes a real matrix to a product of 3 matrices. (<a href=\"\" target=\"_blank\">More on LSA and SVD</a>)\n",
    "\n",
    "\n",
    "<span style=\"color: red; font-weight: bold;\">Takeaway:</span> **Each question will be represented by a vector of length k. comparing the questions will be as easy as performing a cosine similarity between the vectors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing is paramount !\n",
    "\n",
    "\n",
    "<div style=\"border: solid 1px blue; padding: 5px;\"><h4><center><span style=\"color: red;\">If we let Garbage In, we get Garbage Out ! (GIGO)</span><center></h4></div>\n",
    "\n",
    "<br/>\n",
    "The most important data type in this project is Text (questions, tags ...). Unfortunately, if left unpreprocessed, it becomes extremely hard to extract useful information from it.\n",
    "\n",
    "This section's goal, is to prepare the data by simplifying it and removing any noise that migh get in the way between us and the True Information that we want to extract.\n",
    "\n",
    "This simple preprocessing can be easily done online in production, doesn't require a lot of computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags:\n",
    "For some reason, there are many tags which are not used in any question (and they are also not followed by any user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1865 useless tags were found and dropped.\n"
     ]
    }
   ],
   "source": [
    "# Drop tags that are not used in any question and not followed by any user (it will clean a lot of useless stuff)\n",
    "useless_tags = tags[~tags.index.isin(tag_questions['tag_id'].unique())]\n",
    "useless_tags = tags[ (tags.index.isin(useless_tags.index.values)) & (~tags.index.isin(tag_users['tag_id'].values)) ]\n",
    "tags = tags.drop(useless_tags.index)\n",
    "\n",
    "print(f'- {len(useless_tags)} useless tags were found and dropped.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make the following transformations to the tags:\n",
    "* make all tags lowercase.\n",
    "* create a new 'processed' column to hold the processed version of each tag\n",
    "* remove any special characters from the text.\n",
    "* correct some short words (yrs -> years)\n",
    "* lemmatize the tags ( eg. 'wolves' -> 'wolf' )\n",
    "* remove tags without any meaning that are just numbers, just preprositions, pronouns, stop-words ... ('where', 'and', 'the', '10', ...etc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 Tags were filtered out.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags_tag_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34421</th>\n",
       "      <td>#realestate</td>\n",
       "      <td>realestate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29786</th>\n",
       "      <td>deaf-education</td>\n",
       "      <td>deafeducation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name      processed\n",
       "tags_tag_id                               \n",
       "34421           #realestate     realestate\n",
       "29786        deaf-education  deafeducation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing Tags\n",
    "\n",
    "nbr_tags = len(tags)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# some common words / mistakes to filter out too\n",
    "stop_words.update(['want', 'go', 'like', 'aa', 'aaa', 'aaaaaaaaa', \n",
    "                   'good', 'best', 'would', 'get', 'as', 'th', 'k',\n",
    "                   'become', 'know', 'us'])\n",
    "special_characters = f'[{string.punctuation}]'\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "tags['name'] = tags['name'].str.lower()\n",
    "tags.fillna('', inplace=True)\n",
    "tags['processed'] = tags['name'].str.replace(special_characters, '')\n",
    "tags['processed'] = tags['processed'].str.replace('^\\d+$', '') # tags that are just numbers :-/\n",
    "tags['processed'] = tags['processed'].apply(lambda x: lm.lemmatize(x)) # avoid having plurals like 'career' and 'careers'\n",
    "tags['processed'] = tags['processed'].str.replace('^\\w$', '') # single letter tags :-/\n",
    "tags['processed'] = tags['processed'].str.replace(r'(\\d+)(yrs?)', r'\\1year') #\n",
    "tags['processed'] = tags['processed'].apply(lambda x: x if x not in stop_words else '')\n",
    "\n",
    "# Drop tags which are prepositions, pronouns, determiners, wh-adverbs (where, ...)\n",
    "tags_to_drop = []\n",
    "for i, t in tags['processed'].iteritems():\n",
    "    if len(t) > 0 and nltk.pos_tag([t])[0][1] in ['IN', 'PRP', 'WP$', 'PRP$', 'WP', 'DT', 'WRB']:\n",
    "        tags_to_drop.append(i)\n",
    "tag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\n",
    "tags = tags.drop(tags_to_drop)\n",
    "\n",
    "# Drop tags which are just numbers\n",
    "tags_to_drop = tags[tags['name'].str.contains('^\\d+$')].index\n",
    "tag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\n",
    "tags = tags.drop(tags_to_drop)\n",
    "\n",
    "# Drop tags which are just stop words ( after, the , with , ...)\n",
    "tags_to_drop = tags[tags['name'].isin(stop_words)].index\n",
    "tag_questions = tag_questions.drop(tag_questions[tag_questions['tag_id'].isin(tags_to_drop)].index)\n",
    "tags = tags.drop(tags_to_drop)\n",
    "\n",
    "print(f'{nbr_tags - len(tags)} Tags were filtered out.')\n",
    "tags.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* We create a new column 'processed' containing both 'title' & 'body' text, and do the same transformations we did to tags ( remove special characters, lemmatize words and remove stop words ).\n",
    "* Create a new column 'count_answers'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions preprocessed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>processed</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55f90ef541474d6d9ad6f1564135d340</th>\n",
       "      <td>What do colleges and universities look for in applicants?</td>\n",
       "      <td>I've always been told that you should be a \"well-rounded\" person if you want to get accepted to a good college, but that has never made sense to me. If I was a part of a college board I'd want stu...</td>\n",
       "      <td>college university look applicant always told wellrounded person accepted college never made sense part college board student excelled field passionate rather great area alright every area look co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      title      ...      count_answers\n",
       "questions_id                                                                                     ...                   \n",
       "55f90ef541474d6d9ad6f1564135d340  What do colleges and universities look for in applicants?      ...                  1\n",
       "\n",
       "[1 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions Cleaning\n",
    "\n",
    "questions['processed'] = questions['title'] + ' ' + questions['body']\n",
    "questions['processed'] = questions['processed'].str.lower()\n",
    "questions['processed'] = questions['processed'].str.replace('<.*?>', '') # remove html tags\n",
    "questions['processed'] = questions['processed'].str.replace('[-_]', '') # remove separators\n",
    "questions['processed'] = questions['processed'].str.replace(special_characters, ' ') # remove special characters\n",
    "\n",
    "questions['processed'] = questions['processed'].str.replace('\\d+\\s?yrs?', ' years') # single letter tags :-/\n",
    "\n",
    "def lem_question(q):\n",
    "    return \" \".join([lm.lemmatize(w) for w in q.split() if w not in stop_words])\n",
    "questions['processed'] = questions['processed'].apply(lem_question)\n",
    "\n",
    "questions['processed'] = questions['processed'].str.replace(r'(\\d+)($|\\s+)', r'\\2') # remove numbers which are not part of words\n",
    "questions['processed'] = questions['processed'].str.replace(r'(\\d+)([th]|k)', r'\\2') # remove numbers from before th and k\n",
    "\n",
    "\n",
    "# Function to preprocess new questions\n",
    "# TODO: update function to do like above\n",
    "def preprocess_question(q):\n",
    "    q = q.lower()\n",
    "    q = re.sub(\"<.*?>\", \"\", q)\n",
    "    q = re.sub(\"[-_]\", \"\", q)\n",
    "    q = re.sub(\"\\d+\", \"\", q)\n",
    "    q = q.translate(q.maketrans('', '', string.punctuation))\n",
    "    q = \" \".join([lm.lemmatize(t) for t in q.split()])\n",
    "    return q\n",
    "\n",
    "cnt_answers = answers.groupby('question_id').count()[['body']].rename(columns={'body': 'count_answers'})\n",
    "questions = questions.join(cnt_answers)\n",
    "questions['count_answers'] = questions['count_answers'].fillna(0)\n",
    "questions['count_answers'] = questions['count_answers'].astype(int)\n",
    "\n",
    "print('Questions preprocessed.')\n",
    "questions.sample(1)[['title', 'body', 'processed', 'count_answers']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professionals\n",
    "* **Count Answers:** Create a new column 'count_answers' for professionals\n",
    "* **Cleaning the headlines:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professionals preprocessed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>industry</th>\n",
       "      <th>headline</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionals_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f635e282b31045819ac998a120fae0e1</th>\n",
       "      <td>Cambridge, Massachusetts</td>\n",
       "      <td>Internet</td>\n",
       "      <td>software engineering intern at linkedin</td>\n",
       "      <td>2014-02-21 20:25:45 UTC+0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  location      ...      count_answers\n",
       "professionals_id                                                ...                   \n",
       "f635e282b31045819ac998a120fae0e1  Cambridge, Massachusetts      ...                  5\n",
       "\n",
       "[1 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Answers\n",
    "pro_answers_count = answers.groupby('author_id').count()[['question_id']].rename(columns={'question_id': 'count_answers'})\n",
    "professionals = professionals.join(pro_answers_count)\n",
    "professionals['count_answers'] = professionals['count_answers'].fillna(0)\n",
    "professionals['count_answers'] = professionals['count_answers'].astype(int)\n",
    "\n",
    "\n",
    "# Cleaning the headlines\n",
    "professionals['headline'] = professionals['headline'].fillna('')\n",
    "professionals['headline'] = professionals['headline'].str.lower()\n",
    "professionals['headline'] = professionals['headline'].str.replace('--|hello|hello!|hellofresh', '')\n",
    "\n",
    "print('Professionals preprocessed')\n",
    "professionals.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Modeling !\n",
    "\n",
    "Now that we have pre-processed our data, we are ready for the modeling part.\n",
    "\n",
    "The modeling steps are as follows:\n",
    "\n",
    "* **Apply TF-IDF on the hole question corpus.**\n",
    "* **Apply SVD to reduce the dimensionality of the vectors.**\n",
    "* **Construct a Questions Similarity Matrix using The Cosine Similarity function.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape:  (23931, 18761)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Transformation\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words,)\n",
    "Qs = tfidf.fit_transform(questions['processed'])\n",
    "terms = tfidf.get_feature_names()\n",
    "print('TF-IDF matrix shape: ', Qs.shape)\n",
    "#print(f'{len(terms)} terms: ', list(pd.Series(terms).sample(10)), '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after Dimensionality Reduction: (23931, 1000)\n"
     ]
    }
   ],
   "source": [
    "# SVD Transformation\n",
    "\n",
    "NUM_TOPICS = 1000\n",
    "model = TruncatedSVD(n_components=NUM_TOPICS)\n",
    "model_transformer = model.fit(Qs)\n",
    "Qs_transformed = model_transformer.transform(Qs)\n",
    "print('Shape after Dimensionality Reduction:', Qs_transformed.shape)\n",
    "del Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix Shape:  (23931, 23931) \n",
      "\n",
      "CPU times: user 43.5 s, sys: 3.47 s, total: 46.9 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Construct the Questions Similarity Matrix\n",
    "\n",
    "Qs_sim_matrix = cosine_similarity(Qs_transformed, Qs_transformed)\n",
    "print('Similarity Matrix Shape: ', Qs_sim_matrix.shape, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: blue;\">Notes on production:</span>\n",
    "* *Here, we use the totality of the question corpus when constructing the Similarity Matrix, in practice though, the similarity matrix will only be constructed with relatively recent questions ( last 1 or 2 years ), since old questions will not be of any use. Its construction only takes ~ 40 seconds for a ~ 24k x 24k matrix (pretty quick).*\n",
    "* *When in production, the Similarity Matrix & Questions Transformed Matrix must be updated on regular basis, depending on the traffic.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Recommendations Engine\n",
    "\n",
    "In this section, we will build the recommendations engine from scratch using only the techniques previously talked about. Each sub-section will deal with a specific sub-problem.\n",
    "\n",
    "There are two main data structures we will work with:\n",
    "* **The Transformed Questions Matrix**: a Matrix where each row represents a single question encoded in a K dimensional vector\n",
    "* **The Similarity Matrix**: a NxN Matrix (where N is the number of questions) rating the similarity between all pair of questions on a scale of 0 ~ 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professional-to-Questions Mode:\n",
    "In this mode, three types of professionals can be distinguished:\n",
    "* **Hot**: The professional has posted at least one answer.\n",
    "* **Cold**: The professional has never posted an answer, but follows some tags.\n",
    "* **Freezing**: The professional never posted an answer and doesn't follow any tags.\n",
    "\n",
    "**How to deal with the 'Freezing' professional ?**\n",
    "\n",
    "The 'Freezing' professional has most probably registered recently, and doesn't follow any tags. We don't know much about him, the recommendations are more like 'suggestions' with the goal of taking him to the higher categories. \n",
    "\n",
    "We can suggest:\n",
    "* **Exploit:** session-based recommendations which recommend questions similar to questions already visited / upvoted or commented by the professional\n",
    "* **Explore:** popular questions on the platform and newly created ones.\n",
    "\n",
    "\n",
    "**How to deal with the 'Cold' professional ?**\n",
    "\n",
    "Unlike the 'Freezing' professional, the 'Cold' one follows one more tags. This important hint must be fully exploited as followed:\n",
    "* **Exploit:** find relatively recent questions from the tags followed.\n",
    "* **Explore:** find tags similar to the followed tags and do the same.\n",
    "\n",
    "**How to deal with the 'Hot' professional ?**\n",
    "\n",
    "This type of professional has already expressed interest in one or more questions.\n",
    "* **Exploit:** suggest similar questions to the ones answered\n",
    "* **Explore:** suggest relatively recent questions from the tags followed and similar tags\n",
    "\n",
    "### Formulas for Exploit Threshold and Question Scoring (for the 'Hot' professional):\n",
    "\n",
    "Unlike the the two other types of professionals, the optimal Exploit Threshold for the 'Hot' professional is dynamic and changes from a professional to another. Some professionals have only answered one question, while others have answered many. Some professionals have answers which date to a relatively long time, while others have just recently answered a few. **Taking these parameters into consideration affects positively the quality of the recommendations**.\n",
    "\n",
    "* We want our recommender to prioritize questions similar to questions recently answered by the professional\n",
    "* We also don't want to completely ignore older questions.\n",
    "\n",
    "The following formula scores the questions while capturing the notes above:\n",
    "\n",
    "$$ score(x) = \\frac{log (\\frac{x}{\\epsilon})}{log (\\frac{1}{\\epsilon})} $$\n",
    "where:\n",
    "- x is the number of days elapsed between the date question was answered and today\n",
    "- $\\epsilon$ is the maximum number of days after which we no longer consider the question to be relevant\n",
    "\n",
    "The formula gives a score between 0~1 where 1 means that the question is very relevant and should be used as a reference.\n",
    "\n",
    "After the questions get scored, the Exploit Threshold is calculated as follows:\n",
    "\n",
    "$$ threshold = log (\\sqrt{x} + 1) \\cdot \\alpha +  \\epsilon $$\n",
    "where:\n",
    "- x is the number of recently answered questions\n",
    "- $\\alpha$ controls the exploitation intensity (1.35 in the implementation)\n",
    "- $\\epsilon$ is an optional small value term (0.1 on the implementation) added if all answered questions are old ( meaning, that x = 0, see the implementation below )\n",
    "\n",
    "Below is the implementation of the two formulas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_question_answered(days_elapsed):\n",
    "    eps = 370\n",
    "    score = np.log10(days_elapsed*(1/eps)) / (np.log10(1/eps))\n",
    "    score = 0.001 if score < 0 else score # questions that got a score lower than 0 are still given a very low score\n",
    "    return score\n",
    "\n",
    "def calculate_exploit_threshold(answered_question_scores, nbr_recommendations):\n",
    "    nbr_questions_answered = len([s for s in answered_question_scores if s > 0.001])\n",
    "    eps = 0.1 if nbr_questions_answered == 0 else 0\n",
    "    alpha = 1.35\n",
    "    return np.log10(np.sqrt(nbr_questions_answered) + 1) * alpha + eps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next snippet of code builds the recommendation engine using two main functions:**\n",
    "* get_similar_questions: returns similar questions to the one given using the similarity matrix.\n",
    "* recommend_questions_to_professional: given a professional ID, returns top K recommended questions\n",
    "\n",
    "The debug variable below if set to True  makes exploration / exploitation decisions visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "*( Feel free to check the code below collapsed )*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Init important variables\n",
    "today = pd.to_datetime('today')\n",
    "min_date_for_questions = today - np.timedelta64(600, 'D')\n",
    "\n",
    "\n",
    "def choose_random_answered_question(question_score_dic):\n",
    "    random_key = choices(list(question_score_dic.keys()), list(question_score_dic.values()))[0]\n",
    "    return (random_key, question_score_dic[random_key])\n",
    "\n",
    "\n",
    "def choose_random_followed_tag(pro_id):\n",
    "    followed_tags = tag_users[tag_users['user_id'] == pro_id]\n",
    "    return followed_tags.sample(1)['tag_id'].values[0]\n",
    "\n",
    "def get_similar_questions(qid, nbr_questions=10, except_questions_ids=[], prioritize=False):\n",
    "    recommendations = pd.DataFrame([])\n",
    "\n",
    "    #print(qid)\n",
    "    q_dists_row = list(Qs_sim_matrix[questions.index.get_loc(qid)])\n",
    "    for eq_id in except_questions_ids:\n",
    "        #print('removing ', eq_id)\n",
    "        q_dists_row.pop(questions.index.get_loc(eq_id))\n",
    "    q_dists_row = pd.Series(q_dists_row).sort_values(ascending=False)[:100]\n",
    "    q_dists_row = q_dists_row[1:]\n",
    "\n",
    "    if not prioritize:\n",
    "        q_dists_row = q_dists_row[:nbr_questions]\n",
    "        for i, d in q_dists_row.iteritems():\n",
    "            qid = questions.index.values[i]\n",
    "            recommendations = recommendations.append(questions.loc[qid])\n",
    "    else:\n",
    "        qid_to_score = {}\n",
    "        for i, d in q_dists_row.iteritems():\n",
    "            qid = questions.index.values[i]\n",
    "            if d > 0.4:\n",
    "                #print(qid)\n",
    "                q_added = questions.loc[qid, 'date_added']\n",
    "                days_elapsed = (today - q_added) / np.timedelta64(1, 'D')\n",
    "                qid_to_score[qid] = d * days_elapsed\n",
    "        qid_scores = sorted(qid_to_score.items(), key=lambda x: x[1])[:nbr_questions]\n",
    "        for qid, score in qid_scores:\n",
    "            print(q_dists_row[questions.index.get_loc(qid)], qid_to_score[qid]) if debug else None\n",
    "            recommendations = recommendations.append(questions.loc[qid])\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "\n",
    "def recommend_questions_to_professional(pro_id, nbr_recommendations=10):\n",
    "    print('Professional ID:', pro_id )\n",
    "\n",
    "    # tags followed\n",
    "    tags_followed = tag_users[tag_users['user_id'] == pro_id]['tag_id']\n",
    "    tags_followed = tags[tags.index.isin(tags_followed)]\n",
    "    print('Followed Tags: ', tags_followed['name'].values)\n",
    "\n",
    "    # Number of answered questions\n",
    "    cnt_pro_answers = professionals.loc[pro_id, 'count_answers']\n",
    "\n",
    "    # Type of Start\n",
    "    cold_start = (cnt_pro_answers == 0)\n",
    "    freezing_start = (cold_start and len(tags_followed) == 0 )\n",
    "\n",
    "    n = 3 # Nbr of questions per tag\n",
    "    recommendations = pd.DataFrame([])\n",
    "\n",
    "\n",
    "    # Freezing Start\n",
    "    if freezing_start:\n",
    "        print('Freezing ...')\n",
    "        recommendations = recommendations.append(questions[questions['date_added'] > min_date_for_questions].sample(10))\n",
    "\n",
    "    # Cold Start\n",
    "    elif cold_start:\n",
    "        print('Cold', cnt_pro_answers)\n",
    "\n",
    "        qids_from_followed_tags  = tag_questions[tag_questions['tag_id'].isin(tags_followed.index.values)]['question_id'].values\n",
    "        qids_from_followed_tags  = list(questions[(questions.index.isin(qids_from_followed_tags))   & (questions['date_added'] > min_date_for_questions)].sort_values('date_added', ascending=False).index.values)\n",
    "\n",
    "        tags_suggested = tags[tags['processed'].isin(tags_followed['processed'].values)]\n",
    "        tags_suggested = tags_suggested[~tags_suggested.index.isin(tags_followed.index.values)]\n",
    "        print('Suggested Tags: ', tags_suggested['name'].values)\n",
    "        suggested_tags_available = len(tags_suggested) > 0\n",
    "        if suggested_tags_available:\n",
    "            qids_from_suggested_tags = tag_questions[tag_questions['tag_id'].isin(tags_suggested.index.values)]['question_id'].values\n",
    "            qids_from_suggested_tags = list(questions[(questions.index.isin(qids_from_followed_tags))  & (questions['date_added'] > min_date_for_questions)].sort_values('date_added', ascending=False).index.values)\n",
    "            exploit_threshold = .6\n",
    "        else:\n",
    "            exploit_threshold = 1\n",
    "\n",
    "\n",
    "        print('Exploit Threshold: ', exploit_threshold) if debug else None\n",
    "        for i in range(1, nbr_recommendations+1):\n",
    "            if np.random.rand() < exploit_threshold and len(qids_from_followed_tags) > 0:\n",
    "                # Exploit followed tags\n",
    "                print(f'{i}- Exploit followed tags') if debug else None\n",
    "                random_index = choice(qids_from_followed_tags)\n",
    "                q = questions.loc[random_index]\n",
    "                recommendations = recommendations.append(q)\n",
    "                qids_from_followed_tags.remove(random_index)\n",
    "            elif suggested_tags_available and len(qids_from_suggested_tags) > 0:\n",
    "                # Suggest from suggested tags\n",
    "                print(f'{i}- Explore suggested tags') if debug else None\n",
    "                random_index = choice(qids_from_suggested_tags)\n",
    "                q = questions.loc[random_index]\n",
    "                recommendations = recommendations.append(q)\n",
    "                qids_from_suggested_tags.remove(random_index)\n",
    "            else:\n",
    "                # no more questions from the pool\n",
    "                pass\n",
    "\n",
    "    # Hot Start\n",
    "    else:\n",
    "        questions_answered_ids = list(answers[answers['author_id'] == pro_id]['question_id'].values)\n",
    "        questions_answered = questions[questions.index.isin(questions_answered_ids)].sort_values('date_added', ascending=False)\n",
    "        questions_answered_locs = []\n",
    "        for qid in questions_answered_ids:\n",
    "            questions_answered_locs.append(questions.index.get_loc(qid))\n",
    "        \n",
    "        print('Hot, Answered Questions: ', cnt_pro_answers)\n",
    "        #print(questions_answered_locs)\n",
    "        display(questions_answered[['date_added', 'processed', 'count_answers']])\n",
    "        \n",
    "        # calculate questions scores\n",
    "        q_scores = {}\n",
    "        for i, q in questions_answered.iterrows():\n",
    "            days_elapsed = (today - q['date_added'])/np.timedelta64(1, 'D')\n",
    "            q_scores[i] = calculate_score_question_answered(days_elapsed)\n",
    "        print(q_scores) if debug else None\n",
    "\n",
    "        # calculate exploit_threshold\n",
    "        exploit_threshold = calculate_exploit_threshold(list(q_scores.values()), nbr_recommendations)\n",
    "        print('Exploit Threshold:', exploit_threshold) if debug else None\n",
    "        except_qs = []\n",
    "        except_qs += questions_answered_ids\n",
    "        for i in range(nbr_recommendations):\n",
    "\n",
    "            if np.random.rand() < exploit_threshold:\n",
    "                # Exploit\n",
    "                random_q_score = choose_random_answered_question(q_scores)\n",
    "                print('\\nExploit Question', random_q_score) if debug else None\n",
    "                recommendations = recommendations.append(get_similar_questions(random_q_score[0], nbr_questions=1, except_questions_ids=except_qs, prioritize=True))\n",
    "            else:\n",
    "                # Explore\n",
    "                latest_questions = pd.DataFrame([])\n",
    "                for tid in tags_followed.index.values:\n",
    "                    qids = tag_questions[tag_questions['tag_id'] == tid]['question_id'].values\n",
    "                    tag_qs = questions[questions.index.isin(qids)]\n",
    "                    tag_qs = tag_qs[~tag_qs.index.isin(except_qs)]\n",
    "                    if len(tag_qs) > 0:\n",
    "                        tag_qs = tag_qs.sort_values('date_added', ascending=False)\n",
    "                        latest_questions = latest_questions.append(tag_qs.head(3))\n",
    "                #display(latest_questions)\n",
    "                best_question_id = 0\n",
    "                best_distance = float('-inf')\n",
    "                for qid, r in latest_questions.iterrows():\n",
    "                    qloc = questions.index.get_loc(qid)\n",
    "                    for aqloc in questions_answered_locs:\n",
    "                        d = Qs_sim_matrix[qloc, aqloc]\n",
    "                        if best_question_id == 0 or d > best_distance:\n",
    "                            best_question_id = qid\n",
    "                            best_distance = d\n",
    "\n",
    "                print('\\nExplore Tags', best_question_id, best_distance) if debug else None\n",
    "                if best_question_id != 0:\n",
    "                    recommendations = recommendations.append(questions.loc[best_question_id])\n",
    "            except_qs = list(recommendations.index.values)\n",
    "            except_qs += questions_answered_ids\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Testing the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional ID: a5be6c7b5cd64ab984c4609654db33d5\n",
      "Followed Tags:  ['law-practice']\n",
      "Hot, Answered Questions:  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>processed</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2b6c64ebebba4e5e8a42f6a503b153cf</th>\n",
       "      <td>2017-06-23 03:36:12</td>\n",
       "      <td>method studying sat act time planning take act september sat october study simultaneously receive score possibly advice done college testing ivyleague sat act</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652e344c48d417dbaf60423419af230</th>\n",
       "      <td>2017-06-22 11:23:42</td>\n",
       "      <td>career available prevention human trafficking high school student currently enrolled collegiate high school working towards interested fighting sex trafficking interested option far field go major...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1eb92e311dbd420cb848d1e577009726</th>\n",
       "      <td>2017-03-21 13:19:21</td>\n",
       "      <td>studying post first degree law possible arears focus applying post first degree law school year learn new thing believe communication debatable skill sure expect entrance exam interview really app...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_added      ...      count_answers\n",
       "questions_id                                              ...                   \n",
       "2b6c64ebebba4e5e8a42f6a503b153cf 2017-06-23 03:36:12      ...                  6\n",
       "1652e344c48d417dbaf60423419af230 2017-06-22 11:23:42      ...                 10\n",
       "1eb92e311dbd420cb848d1e577009726 2017-03-21 13:19:21      ...                  3\n",
       "\n",
       "[3 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1bed152bd4ce420499cc052799f0ffa3</th>\n",
       "      <td>2019-01-17 19:39:40</td>\n",
       "      <td>Need help deciding which program should I choose Social work or Community worker?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f40dc76a7a5844f3bc71da9f391688e6</th>\n",
       "      <td>2018-07-13 19:46:08</td>\n",
       "      <td>what is law school like an how does it work?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360ca20467f9477791d71082670b3506</th>\n",
       "      <td>2018-07-16 20:46:15</td>\n",
       "      <td>Do you need a law degree to become a lawyer?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336a3900441742f69d79c45f0a5f601d</th>\n",
       "      <td>2018-08-04 15:06:53</td>\n",
       "      <td>What are the best tips  to know to become an assistant district attorney?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5bc0a66a6c004dceb8934df95f15bb4a</th>\n",
       "      <td>2018-05-07 23:56:49</td>\n",
       "      <td>What is it like getting out of law school and trying to get a job?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd78646277de4461970f7d4acfcc5972</th>\n",
       "      <td>2018-05-29 16:37:15</td>\n",
       "      <td>How does a lawyer separate personal values from the law when prosecuting or defending?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c0bab6c198045b8a344b2b40b58717f</th>\n",
       "      <td>2018-06-19 21:01:01</td>\n",
       "      <td>Should I go to law school?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac7997b2cded4e7d87a9ff75acb2cc7c</th>\n",
       "      <td>2018-04-19 20:06:05</td>\n",
       "      <td>What courses are needed to gain a law degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9503dee1f2f748ada2dfc5d7dbb1a33d</th>\n",
       "      <td>2018-04-03 21:43:19</td>\n",
       "      <td>Is it hard for a foreigner that went to American Law School to find work?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ae488d2353742a086afa639a94009e9</th>\n",
       "      <td>2018-03-27 15:48:58</td>\n",
       "      <td>Which law schools have notable programs in international human rights law?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_added                                                                                   title\n",
       "1bed152bd4ce420499cc052799f0ffa3 2019-01-17 19:39:40       Need help deciding which program should I choose Social work or Community worker?\n",
       "f40dc76a7a5844f3bc71da9f391688e6 2018-07-13 19:46:08                                            what is law school like an how does it work?\n",
       "360ca20467f9477791d71082670b3506 2018-07-16 20:46:15                                            Do you need a law degree to become a lawyer?\n",
       "336a3900441742f69d79c45f0a5f601d 2018-08-04 15:06:53               What are the best tips  to know to become an assistant district attorney?\n",
       "5bc0a66a6c004dceb8934df95f15bb4a 2018-05-07 23:56:49                      What is it like getting out of law school and trying to get a job?\n",
       "dd78646277de4461970f7d4acfcc5972 2018-05-29 16:37:15  How does a lawyer separate personal values from the law when prosecuting or defending?\n",
       "1c0bab6c198045b8a344b2b40b58717f 2018-06-19 21:01:01                                                              Should I go to law school?\n",
       "ac7997b2cded4e7d87a9ff75acb2cc7c 2018-04-19 20:06:05                                            What courses are needed to gain a law degree\n",
       "9503dee1f2f748ada2dfc5d7dbb1a33d 2018-04-03 21:43:19               Is it hard for a foreigner that went to American Law School to find work?\n",
       "2ae488d2353742a086afa639a94009e9 2018-03-27 15:48:58              Which law schools have notable programs in international human rights law?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional ID: 6277a1f1a2644c3695e8ca23ea1c4c50\n",
      "Followed Tags:  ['education-management'\n",
      " '#readingspecialist-#educator-#literacyspecialist-#teacherofadults']\n",
      "Cold 0\n",
      "Suggested Tags:  ['educationmanagement']\n",
      "Recommendations: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_added</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2e25ea09c6d842b0adfafe13ebb4b47c</th>\n",
       "      <td>2017-10-12 17:54:41</td>\n",
       "      <td>What are the most lucrative jobs in the Nonprofit sector?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1d01dce85fe4778a27387dd9b22773c</th>\n",
       "      <td>2018-03-20 17:58:04</td>\n",
       "      <td>What is it like to start your own school?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164522e7595649729deebf48cad87e1b</th>\n",
       "      <td>2018-01-30 03:16:43</td>\n",
       "      <td>What helped you decide on your major?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2e25ea09c6d842b0adfafe13ebb4b47c</th>\n",
       "      <td>2017-10-12 17:54:41</td>\n",
       "      <td>What are the most lucrative jobs in the Nonprofit sector?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1860d4512b746a19270e5675efb7b44</th>\n",
       "      <td>2018-02-03 01:09:21</td>\n",
       "      <td>What are some of the most flexible majors?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dd71db6e5a724e019f385a702fde87d5</th>\n",
       "      <td>2017-08-31 18:58:48</td>\n",
       "      <td>How do you manage your classroom and students?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476f5056ac1d4d149194da020cea2c43</th>\n",
       "      <td>2018-01-24 03:41:44</td>\n",
       "      <td>Would it be rude to tell my teacher to stop smoking, if not, how can I put it as gently as possible?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4c8d994d667d4f84828ceb09fc7715e9</th>\n",
       "      <td>2018-01-12 03:39:30</td>\n",
       "      <td>Growing up abroad, all my teachers were international teachers from England, but my question is how does one become an international teacher from America?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbe15b7b17ee4333ad2425bc426eb295</th>\n",
       "      <td>2018-01-17 07:24:37</td>\n",
       "      <td>What is the Best Road to Success in the Educational Field?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1860d4512b746a19270e5675efb7b44</th>\n",
       "      <td>2018-02-03 01:09:21</td>\n",
       "      <td>What are some of the most flexible majors?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          date_added                                                                                                                                                       title\n",
       "2e25ea09c6d842b0adfafe13ebb4b47c 2017-10-12 17:54:41                                                                                                   What are the most lucrative jobs in the Nonprofit sector?\n",
       "c1d01dce85fe4778a27387dd9b22773c 2018-03-20 17:58:04                                                                                                                   What is it like to start your own school?\n",
       "164522e7595649729deebf48cad87e1b 2018-01-30 03:16:43                                                                                                                       What helped you decide on your major?\n",
       "2e25ea09c6d842b0adfafe13ebb4b47c 2017-10-12 17:54:41                                                                                                   What are the most lucrative jobs in the Nonprofit sector?\n",
       "e1860d4512b746a19270e5675efb7b44 2018-02-03 01:09:21                                                                                                                  What are some of the most flexible majors?\n",
       "dd71db6e5a724e019f385a702fde87d5 2017-08-31 18:58:48                                                                                                              How do you manage your classroom and students?\n",
       "476f5056ac1d4d149194da020cea2c43 2018-01-24 03:41:44                                                        Would it be rude to tell my teacher to stop smoking, if not, how can I put it as gently as possible?\n",
       "4c8d994d667d4f84828ceb09fc7715e9 2018-01-12 03:39:30  Growing up abroad, all my teachers were international teachers from England, but my question is how does one become an international teacher from America?\n",
       "fbe15b7b17ee4333ad2425bc426eb295 2018-01-17 07:24:37                                                                                                  What is the Best Road to Success in the Educational Field?\n",
       "e1860d4512b746a19270e5675efb7b44 2018-02-03 01:09:21                                                                                                                  What are some of the most flexible majors?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Hot Professional\n",
    "random_hot_pro_id = professionals[(professionals['count_answers'] > 2) & (professionals['count_answers'] < 5)].sample(1).index.values[0]\n",
    "\n",
    "# Random Cold Professional\n",
    "random_cold_pro_id = professionals[professionals['count_answers'] == 0].sample(1).index.values[0]\n",
    "\n",
    "#for random_pro_id in [random_hot_pro_id, random_cold_pro_id]:\n",
    "for random_pro_id in [random_hot_pro_id, random_cold_pro_id]:\n",
    "    recs = recommend_questions_to_professional(random_pro_id, nbr_recommendations=10)\n",
    "    print('Recommendations: ')\n",
    "    display(recs[['date_added', 'title',]]) if len(recs) > 0 else None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-to-Professionals mode:\n",
    "\n",
    "Given a question, recommend the top K professionals to answer. This mode is used for the 'Immediate' folks.\n",
    "\n",
    "The approach taken is straightforward: recommend professionals who answered similar questions to the one given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_professionals_for_question(qid, nbr_recommendations=10):\n",
    "    similar_questions = get_similar_questions(qid, nbr_questions=10, except_questions_ids=[], prioritize=False)\n",
    "    #display(similar_questions)\n",
    "    answer_author_ids = answers[answers['question_id'].isin(similar_questions.index.values)]['author_id'].values\n",
    "    top_authors_ids = pd.Series(answer_author_ids).value_counts(ascending=False)[:nbr_recommendations].index.values\n",
    "    \n",
    "    \n",
    "    return professionals[professionals.index.isin(top_authors_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Testing the recommender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Question:  2018-03-26 02:37:55\n",
      "Which careers should I look into?\n",
      "My interests include linguistics, english, writing, editing, and psychology. Additionally, I really enjoy learning new things and researching. I also enjoy explaining things to others and tutoring. Are there any careers out there that might suit these interests?\r\n",
      "#linguistics #english #writing-and-editing #research #teaching\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>industry</th>\n",
       "      <th>headline</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>count_answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionals_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9798c8df06244283ba14d30978ec318a</th>\n",
       "      <td>Boston, Massachusetts</td>\n",
       "      <td></td>\n",
       "      <td>senior linguistics developer at luminoso</td>\n",
       "      <td>2015-03-02 22:35:27 UTC+0000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36ff3b3666df400f956f8335cf53e09e</th>\n",
       "      <td>Cleveland, Ohio</td>\n",
       "      <td>Mental Health Care</td>\n",
       "      <td>assist with recognizing and developing potential</td>\n",
       "      <td>2015-10-19 20:56:49 UTC+0000</td>\n",
       "      <td>1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507e62b41e3a4410837fbdb760a6c946</th>\n",
       "      <td>Woodbridge Township, New Jersey</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2017-05-10 15:18:13 UTC+0000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9bf67236d34743768be67bd789dc618e</th>\n",
       "      <td>Pomona, California</td>\n",
       "      <td>Higher Education</td>\n",
       "      <td>retention and graduation specialist</td>\n",
       "      <td>2018-07-07 17:13:04 UTC+0000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e77127a9fc4948a89e65835d410804bf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>IT</td>\n",
       "      <td>product manager</td>\n",
       "      <td>2018-11-14 11:25:22 UTC+0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         location      ...      count_answers\n",
       "professionals_id                                                       ...                   \n",
       "9798c8df06244283ba14d30978ec318a            Boston, Massachusetts      ...                 13\n",
       "36ff3b3666df400f956f8335cf53e09e                  Cleveland, Ohio      ...               1710\n",
       "507e62b41e3a4410837fbdb760a6c946  Woodbridge Township, New Jersey      ...                 14\n",
       "9bf67236d34743768be67bd789dc618e               Pomona, California      ...                 37\n",
       "e77127a9fc4948a89e65835d410804bf                              NaN      ...                  1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_question_index = choice(questions.index.values)\n",
    "print('Random Question: ', questions.loc[random_question_index]['date_added'])\n",
    "print(questions.loc[random_question_index]['title'])\n",
    "print(questions.loc[random_question_index]['body'])\n",
    "recommend_professionals_for_question(random_question_index, nbr_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions in production:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Tag Suggestions for a new question:\n",
    "It is very important to control tags, and use existing ones when possible. The following function suggests tags for a new question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Analyze processed question and extracts implicit tags ( eg. 'computer science' => 'computerscience')\n",
    "def get_tag_suggestions(q_p):\n",
    "    #q_p = preprocess_question(q)\n",
    "    #print(q_p)\n",
    "    q_tokens = nltk.word_tokenize(q_p)\n",
    "    q_tokens_cpy = q_tokens.copy()\n",
    "    \n",
    "    qp_tagged = nltk.pos_tag(q_tokens)\n",
    "    important = []\n",
    "    for t,pos in qp_tagged:\n",
    "        if t not in stop_words and pos == 'NN' and len(tags[tags['processed'] == t]) > 0 :\n",
    "            i = q_tokens.index(t)\n",
    "            #print(len(q_p), t, i)\n",
    "            poses_before_after = []\n",
    "            if i > 0:\n",
    "                poses_before_after.append(nltk.pos_tag([q_tokens[i-1]])[0])\n",
    "            if i < (len(q_tokens)-1):\n",
    "                poses_before_after.append(nltk.pos_tag([q_tokens[i+1]])[0])\n",
    "            for i, bf in enumerate(poses_before_after):\n",
    "                #print(t, bf)\n",
    "                if bf[1] in ['NN', 'NNS', 'JJ', 'JJR', 'VBG']:\n",
    "                    s = f'{t}{bf[0]}' if i == 1 else f'{bf[0]}{t}'\n",
    "                    important.append(s)\n",
    "            q_tokens.remove(t)\n",
    "    important = set(important)\n",
    "    for i in set(important):\n",
    "        if i not in tags['processed'].values or i in q_tokens_cpy:\n",
    "            important.remove(i)\n",
    "    #print(len(important),important)\n",
    "    return important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  I am a student in computer science and I want to be a data scientist but I dont now how to study machine learning and artificial intelligence.\n",
      "Suggestions:  {'computerscience', 'artificialintelligence', 'machinelearning'}\n"
     ]
    }
   ],
   "source": [
    "new_question = 'I am a student in computer science and I want to be a data scientist but I dont now how to study machine learning and artificial intelligence.' \n",
    "p_q = preprocess_question(new_question)\n",
    "suggestions = get_tag_suggestions(p_q)\n",
    "print('Question: ', new_question)\n",
    "print('Suggestions: ', suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to add a new question to DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Generate a random index for adding a question to DB\n",
    "def gen_test_index():\n",
    "    length = np.random.randint(10,15)\n",
    "    letters_digits = string.ascii_lowercase + string.digits\n",
    "    return ''.join(random.sample(letters_digits, length))\n",
    "\n",
    "\n",
    "def add_question_to_db(title, body):\n",
    "    global Qs_transformed\n",
    "    global Qs_sim_matrix\n",
    "    q = title + ' ' + body\n",
    "    q_p = preprocess_question(q)\n",
    "    \n",
    "    tag_suggestions = get_tag_suggestions(q_p)\n",
    "    q_p = q_p + ' ' + ' '.join(tag_suggestions)\n",
    "    \n",
    "    print(q_p)\n",
    "    \n",
    "    author_id = 1 # special if for test ( doesn't exist in DB )\n",
    "    index = gen_test_index()\n",
    "    questions.loc[index] = {'author_id': author_id,'date_added': datetime.datetime.now(),\n",
    "                  'title': title, 'body': body, 'processed': q_p}\n",
    "    \n",
    "    q_transformed = model_transformer.transform(tfidf.transform([q_p]))\n",
    "    Qs_transformed = np.append(Qs_transformed, [q_transformed[0]], axis=0)\n",
    "    #print(Qs_transformed.shape)\n",
    "    \n",
    "    sim_mat_shape = Qs_sim_matrix.shape\n",
    "    #print('Qs_sim_mat shape', sim_mat_shape)\n",
    "    new_sims = cosine_similarity(Qs_transformed[-1].reshape(1,-1), Qs_transformed)[0]\n",
    "    #print('new_sims', new_sims.shape)\n",
    "    Qs_sim_matrix = np.hstack((Qs_sim_matrix, np.zeros((sim_mat_shape[0], 1))))\n",
    "    Qs_sim_matrix = np.vstack((Qs_sim_matrix, np.zeros((sim_mat_shape[0]+1))))\n",
    "    Qs_sim_matrix[-1] = new_sims\n",
    "    Qs_sim_matrix[:, -1] = new_sims\n",
    "    #print(Qs_sim_matrix.shape)\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Future Explorations\n",
    "\n",
    "The proposed system's strengths are **its effectiveness, ease of implementation and ease of maintainance in production.**\n",
    "It uses controlled randomness to encourage new users while keeping engaged professionals in the platform.\n",
    "\n",
    "Some recommendations for future improvements: \n",
    "* Valuable information can be obtained when users open a browsing session ( viewed questions ... ).\n",
    "* Preprocessing of tags and preventing the students from using tags which already exist.\n",
    "* Using recent questions ( last 2 years ) for the similarity matrix.\n",
    "* Using a auto-correction system to reduce the typos made by students.\n",
    "* Using the answers in the model.\n",
    "* Updating the system to decide when to email each professional depending on his interaction with the site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I hope that this Kernel was useful, and see you in the <a href=\"https://www.kaggle.com/hamzael1/kernels\" target=\"_blank\">next one</a> !\n",
    "\n",
    "*PS: upvotes & feedback are welcome !*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
